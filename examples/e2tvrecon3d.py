#!/usr/bin/env python

#
# Author: James Michael Bell, 2014 (jmbell@bcm.edu)
# Copyright (c) 2014 Baylor College of Medicine
#
# This software is issued under a joint BSD/GNU license. You may use the
# source code in this file under either license. However, note that the
# complete EMAN2 and SPARX software packages have some GPL dependencies,
# so you are responsible for compliance with the licenses of these packages
# if you opt to use BSD licensing. The warranty disclaimer below holds
# in either instance.
#
# This complete copyright notice must be included in any revised version of the
# source code. Additional authorship citations may be added, but existing
# author citations must be preserved.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 2111-1307 USA
#

from EMAN2 import *
import os
import sys
import scipy
import time
import ntpath
import copy
import numpy as np
from scipy import sparse
from scipy import ndimage
import shutil
from joblib import Parallel, delayed
import multiprocessing


def get_usage():
	progname = os.path.basename(sys.argv[0])
	usage = progname + """ [options]
	e2tvrecon3d.py reconstructs a 3D tomogram from a tilt series and tlt tilt 
	angles file. In order to reconstruct the original image, we minimize a 
	function that is the sum of a L2 data fit term and the total variation of 
	the image. Proximal iterations using the Fast Iterative Shrinking & 
	Thresholding Algorithm (FISTA) are used.
	"""
	return usage


def print_usage():
	usage = get_usage()
	print "usage " + usage;
	print "Please run '" + progname + " -h' for detailed options"


def main():
	parser = EMArgumentParser(usage=get_usage())
	parser.add_argument("--tiltseries", default=None, help="The input projections. Project should usually have the xform.projection header attribute, which is used for slice insertion")
	parser.add_argument("--tlt", type=str, default=None, help="An imod tlt file containing alignment angles. If specified slices will be inserted using these angles in the IMOD convention")
	parser.add_argument("--output", default="threed.hdf", help="Output reconstructed tomogram file name.")
	parser.add_argument("--path",type=str,default='tvrecon_3d',help="Directory in which results will be stored.")
	parser.add_argument("--noclean",action="store_true",default=False, help="If specified, the program will not delete the excess files generated by this program.")
	parser.add_argument("--niters", default=10, type=int, help="Specify the number of iterative reconstructions to complete before returning the final reconstructed volume. The default number is 50")
	parser.add_argument("--beta", default=1.0, type=float, help="Specify the total-variation penalization/regularization weight parameter 'beta'. The default is 5.0.")
	parser.add_argument("--subpix", default=2, type=int, help="Specify the number of linear subdivisions used to compute the projection of one image pixel onto a detector pixel.")
	parser.add_argument("--calcfsc", type=str, default=None, help="If a reference file is specified, e2tvrecon3d will compute an FSC plot between the 3D reconstructed volume and that file.")
	parser.add_argument("--verbose", "-v", dest="verbose", action="store", metavar="n", type=int, default=0, help="verbose level [0-9], higner number means higher level of verboseness")
	parser.add_argument("--parallel", action="store_true", default=False, help="If specified, reconstruction computations will be performed in parallel.")
	parser.add_argument("--ppid", type=int, help="Set the PID of the parent process, used for cross platform PPID", default=-1)
	(options, args) = parser.parse_args()
	
	if options.tiltseries:
		hdr=EMData( options.tiltseries, 0 , True)
		nslices = EMUtil.get_image_count( options.tiltseries )
		apix=hdr['apix_x']
		xsize=hdr['nx']
		ysize=hdr['ny']
	else: 
		print "You must specficy --tiltseries"
		exit(1)
		
	if options.tlt:
		tiltangles = np.asarray([ float( i ) for i in file( options.tlt , "r" ) ])
		tiltangles = tiltangles.tolist()
		nslices = len( tiltangles )
	else:
		print "You must specficy --tlt"
		exit(1)
	
	if options.niters: 
		niters = int(options.niters)
	
	beta = 1.0
	if options.beta: 
		beta = float(options.beta)
		if beta < 0:
			print "Parameter beta must be a positive, real number."
			exit(1)
	
	if options.subpix: 
		subpix = int(options.subpix)
	else: 
		subpix = 1
	
	if options.output: 
		outfilename = options.output
	else:
		outfilename = "threed.hdf"
	
	if options.parallel:
		num_cores = multiprocessing.cpu_count()
		if options.verbose > 1:
			print "Parallel processing across %i cores"%(num_cores)
	
	logger=E2init(sys.argv,options.ppid)
	if options.verbose > 1: 
		print "e2tvrecon3d.py"
	
	# Create new output directory for this instance
	if options.verbose > 2: 
		print "Generating instance directory..."
	options = makepath( options, options.path)
	rootpath = os.getcwd()
	options.path = rootpath + "/" + options.path
	
	if options.verbose > 2: 
		print "Linking tilt series file to instance directory..."
	pathname = os.path.dirname(os.path.abspath( options.tiltseries ))
	filename = ntpath.basename( options.tiltseries )
	linkfrom = pathname + "/" + filename
	linkto = options.path + "/" + filename
	os.symlink( linkfrom, linkto )
	
	if options.verbose > 2: 
		print "Linking tilt angles file to instance directory..."
	pathname = os.path.dirname(os.path.abspath( options.tlt ))
	filename = ntpath.basename( options.tlt )
	linkfrom = pathname + "/" + filename
	linkto = options.path + "/" + filename
	os.symlink( linkfrom, linkto )
	
	# Generate one projection operator for all 2D reconstructions
	if options.parallel:
		if options.verbose > 2: 
			print "Building projection operator..."
		projection_operator = build_projection_operator( tiltangles, xsize, nslices, None, subpix, 0, None )
		projection_operator.copy()
	
	# Generate sinograms
	if options.verbose > 2: 
		print "Generating %i sinograms..."%(ysize)
	if options.parallel:
		Parallel( n_jobs = num_cores )( delayed( make_sinogram )( options, y, ysize, xsize, nslices ) for y in range( ysize ))
	else:
		gen_sinograms(options, xsize, ysize)
	
	if options.verbose > 1:
		print "Performing 2D Reconstruction of All Generated Sinograms"
	
	os.chdir(options.path)
	if options.parallel:
		sinograms = []
		for fname in os.listdir(options.path):
			if "sinogram" in fname:
				sinograms.append(fname)
		Parallel( n_jobs = num_cores )( delayed( twod_recon )( sinogram, y, beta, subpix, projection_operator, tiltangles, nslices, options.verbose, niters ) for y, sinogram in enumerate(sinograms))
		np_recons=[]
		for fname in os.listdir( '.' ):
			if "slice_" in fname:
				recon = EMData( fname, 0, True )
				np_recon = recon.numpy().copy()
				np_recons.append(np_recon)
		reconstack = np.dstack( np_recons )
		threed_recon = from_numpy( reconstack )
		threed_recon['apix_x']=apix
		threed_recon['apix_y']=apix
		threed_recon['apix_z']=apix
		threed_recon.write_image( outfilename )
	else:
		i = 1
		for fname in os.listdir(options.path):
			if "sinogram" in fname:
				inputpath = fname
				twodpath = "twod.hdf"
				verbosity = str(options.verbose)
				tlt = options.tlt
				inputbeta = str(beta)
				if i >= 1000:
					reconpath = "slice_" + str(i)
				elif i >= 100:
					reconpath = "slice_0" + str(i)
				elif i >= 10:
					reconpath = "slice_00" + str(i)
				else:
					reconpath = "slice_000" + str(i)
				p = subprocess.Popen("e2tvrecon2d.py --tiltseries %s --tlt %s --path %s --output %s --beta %s -v %s --subpix %s"%(inputpath, tlt, reconpath, twodpath, inputbeta, verbosity, str(subpix)), shell=True)
				p_status = p.wait()
				i += 1
		np_recons=[]
		for pname in os.listdir( '.' ):
			if "slice_" in pname:
				for fname in os.listdir( pname ):
					if "twod" in fname:
						recon = EMData( pname + "/" + fname, 0 )
						np_recon = recon.numpy().copy()
						np_recons.append(np_recon)
		reconstack = np.dstack( np_recons )
		threed_recon = from_numpy( reconstack )
		threed_recon['apix_x']=apix
		threed_recon['apix_y']=apix
		threed_recon['apix_z']=apix
		threed_recon.write_image( outfilename )
	
	if options.noclean != True:
		if options.verbose > 1: 
			print "Cleaning up current working directory..."
		for fname in os.listdir(options.path):
			if "sinogram_" in fname:
				os.remove( fname )
			if "slice_" in fname and not options.parallel:
				shutil.rmtree( fname )
	
	if options.calcfsc != None:
		if options.verbose > 3: print "Generating an FSC plot..."
		fsc_file = options.path + "/" + "fsc.txt"
		reference = options.fsc
		os.popen("e2proc3d.py %s %s --calcfsc %s"%( outfilename, fsc_file, reference ))
	
	E2end(logger)
	if options.verbose > 1: print "Exiting"
	return


def make_sinogram( options, y, xlen, ylen, num_imgs ):
	"""
	Generates one 2D sinogram for a single specified pixel along the y axis of a tiltseries. All sinograms are written to disk. 
	
	The 'make_sinogram' is a parallelized version of 'gen_sinograms'. As such, it is called multiple times simultaneously to achieve the same result as 'gen_sinograms' in a fraction of the time.
	"""
	r = Region( 0, y, xlen, 1 )
	for imgnum in range( num_imgs ):
		prj = EMData( options.tiltseries, imgnum, False, r )
		if y >= 1000:
			prj.write_image(options.path + "/sinogram_"+str(y)+".hdf", imgnum)
		elif y >= 100:
			prj.write_image(options.path + "/sinogram_0"+str(y)+".hdf", imgnum)
		elif y >= 10:
			prj.write_image(options.path + "/sinogram_00"+str(y)+".hdf", imgnum)
		else:
			prj.write_image(options.path + "/sinogram_000"+str(y)+".hdf", imgnum)
	if options.verbose > 2:
		print "Generated sinogram %i of %i" %( y+1, ylen )
	return


def gen_sinograms( options, xlen, ylen ):
	"""
	Generates one 2D sinogram for each pixel along the y axis of a tiltseries. All sinograms are written to disk. 
	
	The 'gen_sinograms' function constructs sinograms in series for each y-pixel, whereas 'make_sinogram' is used to generate the y-pixel sinograms in parallel.
	"""
	num_imgs = EMUtil.get_image_count( options.tiltseries )
	for y in range( ylen ):
		r = Region( 0, y, xlen, 1 )
		for imgnum in range( num_imgs ):
			prj = EMData( options.tiltseries, imgnum, False, r )
			if y >= 1000:
				prj.write_image(options.path + "/sinogram_"+str(y)+".hdf", imgnum)
			elif y >= 100:
				prj.write_image(options.path + "/sinogram_0"+str(y)+".hdf", imgnum)
			elif y >= 10:
				prj.write_image(options.path + "/sinogram_00"+str(y)+".hdf", imgnum)
			else:
				prj.write_image(options.path + "/sinogram_000"+str(y)+".hdf", imgnum)
		if options.verbose > 2:
			print "Generated sinogram %i of %i" %( y+1, ylen )
	return


def twod_recon(sinogram, y, beta, subpix, projection_operator, tiltangles, nslices, niters, verbosity):
	if y >= 1000:
		twodpath = "slice_" + str(y) + ".hdf"
	elif y >= 100:
		twodpath = "slice_0" + str(y) + ".hdf"
	elif y >= 10:
		twodpath = "slice_00" + str(y) + ".hdf"
	else:
		twodpath = "slice_000" + str(y) + ".hdf"
	
	data, xlen = get_data( sinogram, nslices, verbosity )
	
	projections = data.ravel()[:, np.newaxis]
	
	if verbosity > 2: print "Starting Reconstruction..."
	
	t1 = time.time()
	recon, energies = fista_tv( tiltangles, projections, beta, niters, projection_operator, subpix )
	t2 = time.time()
	
	if verbosity > 3: print "Reconstruction completed in %s s"%(str(t2-t1))
	
	# Store reconstruction in instance outfile directory
	cwd = os.getcwd()
	outpath = cwd + "/" + twodpath
	from_numpy( recon[-1] ).write_image( outpath, 0 )
	return


def get_data( sinogram, nslices, verbosity ):
	"""
	Read an input image as a numpy array and return its length in x and itself as type float 32.
	"""
	if verbosity > 3:
		print "Reading Projections from %s"%(sinogram)
	npstack = []
	for i in range( nslices ):
		img = EMData( sinogram, i )
		np_img = img.numpy().copy()
		npstack.append( np_img )
	data = np.asarray( npstack )
	xlen = img["nx"]
	return data.astype( np.float32 ), xlen


def build_projection_operator( angles, l_x, n_dir=None, l_det=None, subpix=1, offset=0, pixels_mask=None ):
	"""
	Compute the tomography design matrix.
		
	Parameters
	----------
	angles : array of floats
		angles at which projections will be taken
	
	l_x : int
		linear size of image array
	
	n_dir : int, default l_x
		number of angles at which projections are acquired. n_dir projection 
		angles are regularly spaced between 0 and 180.
		
	l_det : int, default is l_x
		number of pixels in the detector. If l_det is not specified, we suppose 
		that l_det = l_x.
	
	subpix : int, default 1
		number of linear subdivisions used to compute the projection of one 
		image pixel onto a detector pixel.
	
	offset : int, default 0
		width of the strip of image pixels not covered by the detector.
	
	pixels_mask : 1-d ndarray of size l_x**2
		mask of pixels to keep in the matrix (useful for to removeing pixels 
		inside or outside of a circle, for example)
		
	Returns
	-------
	p : sparse matrix of shape (n_dir l_x, l_x**2), in csr format
		Tomography design matrix. The csr (compressed sparse row) allows for 
		efficient subsequent matrix multiplication. The dtype of the elements is 
		float32, in order to save memory.	
	"""
	if l_det is None:
		l_det = l_x
	X, Y = _generate_center_coordinates(subpix*l_x)
	X *= 1./subpix
	Y *= 1./subpix
	Xbig, Ybig = _generate_center_coordinates(l_det)
	Xbig *= (l_x - 2*offset) / float(l_det)
	orig = Xbig.min()
	labels = None
	if subpix > 1:
		# Block-group subpixels
		Xlab, Ylab = np.mgrid[:subpix * l_x, :subpix * l_x]
		labels = (l_x * (Xlab / subpix) + Ylab / subpix).ravel()
	if n_dir is None:
		n_dir = l_x
	weights, data_inds, detector_inds = [], [], []
	# Indices for data pixels. For each data, one data pixel
	# will contribute to the value of two detector pixels.
	for i, angle in enumerate(angles):
		# rotate data pixels centers
		Xrot = np.cos(angle*np.pi/180.) * X - np.sin(angle*np.pi/180.) * Y
		# compute linear interpolation weights
		inds, dat_inds, w = _weights_fast(Xrot, dx=(l_x - 2*offset)/float(l_det), orig=orig, labels=labels)
		# crop projections outside the detector
		mask = np.logical_and(inds >= 0, inds < l_det)
		weights.append(w[mask])
		detector_inds.append((inds[mask] + i * l_det).astype(np.int32))
		data_inds.append(dat_inds[mask])
	weights = np.concatenate(weights)
	weights /= subpix**2
	detector_inds = np.concatenate(detector_inds)
	data_inds = np.concatenate(data_inds)
	if pixels_mask is not None:
		if pixels_mask.ndim > 1:
			pixels_mask = pixels_mask.ravel()
		mask = pixels_mask[data_inds]
		data_inds = data_inds[mask]
		data_inds = rank_order(data_inds)[0]
		detector_inds = detector_inds[mask]
		weights = weights[mask]
	proj_operator = sparse.coo_matrix((weights, (detector_inds, data_inds)))
	return sparse.csr_matrix(proj_operator)


def _generate_center_coordinates(l_x):
	"""
	Compute the coordinates of pixels centers for an image of
	linear size l_x
	"""
	l_x = float(l_x)
	X, Y = np.mgrid[:l_x, :l_x]
	center = l_x / 2.
	X += 0.5 - center
	Y += 0.5 - center
	return X, Y


def _weights_fast(x, dx=1, orig=0, labels=None):
	"""
	Compute linear interpolation weights for projection array `x`
	and regularly spaced detector pixels separated by `dx` and
	starting at `orig`.
	"""
	x = np.ravel(x)
	floor_x = np.floor((x - orig) / dx).astype(np.int32)
	alpha = ((x - orig - floor_x * dx) / dx).astype(np.float32)
	inds = np.hstack((floor_x, floor_x + 1))
	weights = np.hstack((1 - alpha, alpha))
	data_inds = np.arange(x.size, dtype=np.int32)
	data_inds = np.hstack((data_inds, data_inds))
	if labels is not None:
		data_inds = np.hstack((labels, labels))
		order = np.argsort(inds)
		inds, data_inds, weights = inds[order], data_inds[order], weights[order]
		steps = np.nonzero(np.diff(inds) > 0)[0] + 1
		steps = np.concatenate(([0], steps))
		inds_s, data_inds_s, weights_s = [], [], []
		for i in range(len(steps) - 1):
			d, w = data_inds[steps[i]:steps[i+1]], weights[steps[i]:steps[i+1]]
			count = np.bincount(d, weights=w)
			mask = count>0
			w = count[mask]
			weights_s.append(w)
			datind = np.arange(len(mask))[mask] 
			data_inds_s.append(datind)
			detind = inds[steps[i]]*np.ones(mask.sum()) 
			inds_s.append(detind)
		inds = np.concatenate(inds_s)
		data_inds = np.concatenate(data_inds_s)
		weights = np.concatenate(weights_s)
	return inds, data_inds, weights


# FISTA ALGORITHM
def fista_tv( angles, y, beta, niter, H, verbose=0, mask=None):
	"""
	TV regression using FISTA algorithm
	(Fast Iterative Shrinkage/Thresholding Algorithm)
	
	Parameters
	----------
	
	y : ndarray of floats
		Measures (tomography projection). If H is given, y is a column
		vector. If H is not given, y is a 2-D array where each line
		is a projection along a different angle
	
	beta : float
		weight of TV norm
	
	niter : number of forward-backward iterations to perform
	
	H : sparse matrix
		tomography design matrix. Should be in csr format.
	
	mask : array of bools
	
	Returns
	-------
	
	res : list
		list of iterates of the reconstructed images
	
	energies : list
		values of the function to be minimized at the different
		iterations. Its values should be decreasing.
	
	Notes
	-----
	This algorithm minimizes iteratively the energy
	
	E(x) = 1/2 || H x - y ||^2 + beta TV bet(x) = f(x) + beta TV(x)
	
	by forward - backward iterations:
	
	u_n = prox_{gamma beta TV}(x_n - gamma nabla f(x_n)))
	t_{n+1} = 1/2 * (1 + sqrt(1 + 4 t_n^2))
	x_{n+1} = u_n + (t_n - 1)/t_{n+1} * (u_n - u_{n-1})
	
	References
	----------
	
	A. Beck and M. Teboulle (2009). A fast iterative
	shrinkage-thresholding algorithm for linear inverse problems.
	SIAM J. Imaging Sci., 2(1):183-202.
	
	Nelly Pustelnik's thesis (in French),
	http://tel.archives-ouvertes.fr/tel-00559126_v4/
	Paragraph 3.3.1-c p. 69 , FISTA
	"""
	n_meas, n_pix = H.shape
	if mask is not None:
		l = len(mask)
	else:
		l = int(np.sqrt(n_pix))
	n_angles = len(angles)
	Ht = sparse.csr_matrix(H.transpose())
	x0 = np.zeros(n_pix)[:, np.newaxis]
	res, energies = [], []
	gamma = .9/ (l * n_angles)
	x = x0
	u_old = np.zeros((l, l))
	t_old = 1
	for i in range(niter):
		if verbose:
			print i
		eps = 1.e-4
		err = H * x - y
		back_proj = Ht * err
		tmp = x - gamma * back_proj
		if mask is not None:
			tmp2d = np.zeros((l, l))
			tmp2d[mask] = tmp.ravel()
		else:
			tmp2d = tmp.reshape((l, l))
		u_n = tv_denoise_fista(tmp2d, weight=beta*gamma, eps=eps)
		t_new = (1 + np.sqrt(1 + 4 * t_old**2))/2.
		t_old = t_new
		x = u_n + (t_old - 1)/t_new * (u_n - u_old)
		u_old = u_n
		res.append(x)
		data_fidelity_err = 1./2 * (err**2).sum()
		tv_value = beta * tv_norm(x)
		# tv_norm_anisotropic(x)
		# tv_l0_norm(x)
		energy = data_fidelity_err + tv_value
		energies.append(energy)
		if mask is not None:
			x = x[mask][:, np.newaxis]
		else:
			x = x.ravel()[:, np.newaxis]
	return res, energies


def tv_denoise_fista(im, weight=50, eps=5.e-5, n_iter_max=200, check_gap_frequency=3):
	"""
	Perform total-variation denoising on 2-d and 3-d images
	
	Find the argmin `res` of
		1/2 * ||im - res||^2 + weight * TV(res),
	
	where TV is the isotropic l1 norm of the gradient.
	
	Parameters
	----------
	im: ndarray of floats (2-d or 3-d)
		input data to be denoised. `im` can be of any numeric type,
		but it is cast into an ndarray of floats for the computation
		of the denoised image.
	
	weight: float, optional
		denoising weight. The greater ``weight``, the more denoising (at
		the expense of fidelity to ``input``)
	
	eps: float, optional
		precision required. The distance to the exact solution is computed
		by the dual gap of the optimization problem and rescaled by the l2
		norm of the image (for contrast invariance).
	
	n_iter_max: int, optional
		maximal number of iterations used for the optimization.
	
	Returns
	-------
	out: ndarray
		denoised array
	
	Notes
	-----
	The principle of total variation denoising is explained in
	http://en.wikipedia.org/wiki/Total_variation_denoising
	
	The principle of total variation denoising is to minimize the
	total variation of the image, which can be roughly described as
	the integral of the norm of the image gradient. Total variation
	denoising tends to produce "cartoon-like" images, that is,
	piecewise-constant images.
	
	This function implements the FISTA (Fast Iterative Shrinkage
	Thresholding Algorithm) algorithm of Beck et Teboulle, adapted to
	total variation denoising in "Fast gradient-based algorithms for
	constrained total variation image denoising and deblurring problems"
	(2009).
	"""
	if not im.dtype.kind == 'f':
		im = im.astype(np.float)
	shape = [im.ndim, ] + list(im.shape)
	grad_im = np.zeros(shape)
	grad_aux = np.zeros(shape)
	t = 1.
	i = 0
	while i < n_iter_max:
		error = weight * div(grad_aux) - im
		grad_tmp = gradient(error)
		grad_tmp *= 1./ (8 * weight)
		grad_aux += grad_tmp
		grad_tmp = _projector_on_dual(grad_aux)
		t_new = 1. / 2 * (1 + np.sqrt(1 + 4 * t**2))
		t_factor = (t - 1) / t_new
		grad_aux = (1 + t_factor) * grad_tmp - t_factor * grad_im
		grad_im = grad_tmp
		t = t_new
		if (i % check_gap_frequency) == 0:
			gap = weight * div(grad_im)
			new = im - gap
			dgap = dual_gap(im, new, gap, weight)
			if dgap < eps:
				break
		i += 1
	return new


# TV NORMS
def tv_norm(img):
	"""Compute the (isotropic) TV norm of an image"""
	grad_x1 = np.diff(img, axis=0)
	grad_x2 = np.diff(img, axis=1)
	return np.sqrt(grad_x1[:, :-1]**2 + grad_x2[:-1, :]**2).sum()

def tv_l0_norm( img ):
	"""Compute the (isotropic) TV norm of a 2D image"""
	grad_x1 = np.diff(img, axis=0)
	grad_x2 = np.diff(img, axis=1)
	return (grad_x1[:, :-1]**2 + grad_x2[:-1, :]**2 > 0).mean()

def tv_norm_anisotropic( img ):
	"""Compute the anisotropic TV norm of an image"""
	grad_x1 = np.diff(img, axis=0)
	grad_x2 = np.diff(img, axis=1)
	return np.abs(grad_x1[:, :-1]).sum() + np.abs(grad_x2[:-1, :]).sum()


def rank_order(image):
	"""Return an image of the same shape where each pixel is the index of the 
	pixel value in the ascending order of the unique values of `image`, aka the 
	rank-order value.
	
	Parameters
	----------
	image: ndarray
	
	Returns
	-------
	labels: ndarray of type np.uint32, of shape image.shape
		New array where each pixel has the rank-order value of the corresponding 
		pixel in `image`. Pixel values are between 0 and n - 1, where n is the 
		number of distinct unique values in ''image`.
	
	original_values: 1-d ndarray
		Unique original values of `image`
	
	Examples
	--------
	>>> a = np.array([[1, 4, 5], [4, 4, 1], [5, 1, 1]])
	>>> a
	array([[1, 4, 5],
		[4, 4, 1],
		[5, 1, 1]])
	>>> rank_order(a)
	(array([[0, 1, 2],
		[1, 1, 0],
		[2, 0, 0]], dtype=uint32), array([1, 4, 5]))
	>>> b = np.array([-1., 2.5, 3.1, 2.5])
	>>> rank_order(b)
	(array([0, 1, 2, 1], dtype=uint32), array([-1. ,  2.5,  3.1]))
	"""
	flat_image = image.ravel()
	sort_order = flat_image.argsort().astype(numpy.uint32)
	flat_image = flat_image[sort_order]
	sort_rank = numpy.zeros_like(sort_order)
	is_different = flat_image[:-1] != flat_image[1:]
	numpy.cumsum(is_different, out=sort_rank[1:])
	original_values = numpy.zeros((sort_rank[-1] + 1,), image.dtype)
	original_values[0] = flat_image[0]
	original_values[1:] = flat_image[1:][is_different]
	int_image = numpy.zeros_like(sort_order)
	int_image[sort_order] = sort_rank
	return (int_image.reshape(image.shape), original_values)


def div(grad):
	""" Compute divergence of image gradient """
	res = np.zeros(grad.shape[1:])
	for d in range(grad.shape[0]):
		this_grad = np.rollaxis(grad[d], d)
		this_res = np.rollaxis(res, d)
		this_res[:-1] += this_grad[:-1]
		this_res[1:-1] -= this_grad[:-2]
		this_res[-1] -= this_grad[-2]
	return res


def gradient(img):
	""" 
	Compute gradient of an image
	
	Parameters
	===========
	img: ndarray
		N-dimensional image
	
	Returns
	=======
	gradient: ndarray
		Gradient of the image: the i-th component along the first axis is the 
		gradient along the i-th axis of the original array img
	"""
	shape = [img.ndim, ] + list(img.shape)
	gradient = np.zeros(shape, dtype=img.dtype)
	# 'Clever' code to have a view of the gradient with dimension i stop at -1
	slice_all = [0, slice(None, -1),]
	for d in range(img.ndim):
		gradient[slice_all] = np.diff(img, axis=d)
		slice_all[0] = d + 1
		slice_all.insert(1, slice(None))
	return gradient


def _projector_on_dual(grad):
	"""
	Modifies in place the gradient to project iton the L2 unit ball
	"""
	norm = np.maximum(np.sqrt(np.sum(grad**2, 0)), 1.)
	for grad_comp in grad:
		grad_comp /= norm
	return grad


def dual_gap(im, new, gap, weight):
	"""
	dual gap of total variation denoising
	see "Total variation regularization for fMRI-based prediction of behavior", 
	by Michel et al. (2011) for a derivation of the dual gap
	"""
	im_norm = (im**2).sum()
	gx, gy = np.zeros_like(new), np.zeros_like(new)
	gx[:-1] = np.diff(new, axis=0)
	gy[:, :-1] = np.diff(new, axis=1)
	if im.ndim == 3:
		gz = np.zeros_like(new)
		gz[..., :-1] = np.diff(new, axis=2)
		tv_new = 2 * weight * np.sqrt(gx**2 + gy**2 + gz**2).sum()
	else:
		tv_new = 2 * weight * np.sqrt(gx**2 + gy**2).sum()
	dual_gap = (gap**2).sum() + tv_new - im_norm + (new**2).sum()
	return 0.5 / im_norm * dual_gap


def makepath(options, stem=''):
	if options.verbose > 5: print "makepath function called"
	if options.path and ("/" in options.path or "#" in options.path):
		print "Path specifier should be the name of a subdirectory to use in the current directory."
		print "Neither '/' or '#' can be included. Please edit your --path argument accordingly."
		sys.exit(1)
	if not options.path:
		options.path = stem + '_01'
		if options.verbose > 5:
			print "--path was not specified, therefore it will have the default value"
	files=os.listdir(os.getcwd())
	while options.path in files:
		if '_' not in options.path:
			options.path = options.path + '_00'
		else:
			#jobtag=''
			components=options.path.split('_')
			if components[-1].isdigit():
				components[-1] = str(int(components[-1])+1).zfill(2)
			else:
				components.append('00')
			options.path = '_'.join(components)
	if options.verbose > 5: print "The new options.path is", options.path
	if options.path not in files:
		if options.verbose > 5:
			print "Creating the following path: ", options.path
		os.system('mkdir ' + options.path)
	return options


if __name__=="__main__":
	main()

