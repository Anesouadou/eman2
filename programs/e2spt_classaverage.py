#!/usr/bin/env python

#
# Author: Jesus Galaz-Montoya 03/2011, (based on Steven Ludtke's initial implementation [02/15/2011] of Jesus's older scripts).
# Last modification: 16/Sept/2014
#
# Copyright (c) 2011 Baylor College of Medicine
#
# This software is issued under a joint BSD/GNU license. You may use the
# source code in this file under either license. However, note that the
# complete EMAN2 and SPARX software packages have some GPL dependencies,
# so you are responsible for compliance with the licenses of these packages
# if you opt to use BSD licensing. The warranty disclaimer below holds
# in either instance.
#
# This complete copyright notice must be included in any revised version of the
# source code. Additional authorship citations may be added, but existing
# author citations must be preserved.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  2111-1307 USA
#
#

from EMAN2 import *
import math
import numpy
from copy import deepcopy
import os
import sys
import random
from random import choice
from pprint import pprint
from EMAN2jsondb import JSTask,jsonclasses
import datetime



def main():
	progname = os.path.basename(sys.argv[0])
	usage = """prog <output> [options]

	This program produces iterative class-averages akin to those generated by e2classaverage, 
	but for stacks of 3-D Volumes.
	Normal usage is to provide a stack of particle volumes and a classification matrix file 
	(if you have more than one class) defining class membership. 
	Members of each class are then iteratively aligned to each other (within the class) and 
	averaged together. 
	It is also possible to use this program on all of the volumes in a single stack without
	providing a classification matrix.

	Specify preprocessing options through --lowpass, --highpass, --mask, --normproc, --thresh, 
	--preprocess and --shrink. These take EMAN2 processors (to see a list, type e2help.py processors at
	the command line).
	
	Notice that the alignment is broken down into two step: 1) Coarse alignment and 2) Fine 
	alignment. This is done for speed optimization. By default, the particles are preprocessed
	THE SAME was for Coarse and Fine alignment, unless you supply --notprocfinelinecoarse.
	In this case, the particles will be preprocessed with default parameters for fine alignment.
	To specify or inactivate any preprocessing for fine alignment, do so through fine 
	alignment parameters:
	--lowpassfine, --highpassfine, --preprocessfine and --shrinkfine (notice the aberrant "r" in the latter).
	
	"""
			
	parser = EMArgumentParser(usage=usage,version=EMANVERSION)
	
	parser.add_header(name="caheader", help='Options below this label are specific to e2spt_classaverage', title="### e2spt_classaverage options ###", default=None, guitype='filebox', row=3, col=0, rowspan=1, colspan=3, mode='alignment,breaksym')
	parser.add_argument("--path",type=str,default=None,help="Directory to store results in. The default is a numbered series of directories containing the prefix 'spt'; for example, spt_02 will be the directory by default if 'spt_01' already exists.")
	parser.add_argument("--input", type=str, help="The name of the input volume stack. MUST be HDF or BDB, since volume stack support is required.", default=None, guitype='filebox', browser='EMSubTomosTable(withmodal=True,multiselect=False)', row=0, col=0, rowspan=1, colspan=3, mode='alignment,breaksym')
	parser.add_argument("--output", type=str, help="""The name of the output class-average stack. 
		MUST be HDF or BDB, since volume stack support is required.""", default='avg.hdf', 
		guitype='strbox', row=2, col=0, rowspan=1, colspan=3, mode='alignment,breaksym')
	parser.add_argument("--oneclass", type=int, help="Create only a single class-average. Specify the class number.",default=0)
	parser.add_argument("--classmx", type=str, help="The name of the classification matrix specifying how particles in 'input' should be grouped. If omitted, all particles will be averaged.", default='')
	parser.add_argument("--ref", type=str, help="Reference image(s). Used as an initial alignment reference and for final orientation adjustment if present. This is typically the projections that were used for classification.", default=None, guitype='filebox', browser='EMBrowserWidget(withmodal=True,multiselect=True)', filecheck=False, row=1, col=0, rowspan=1, colspan=3, mode='alignment')
	
	parser.add_argument("--refpreprocess",action="store_true",default=False,help="""This 
		will preprocess the reference identically to the particles. It is off by default, but it is internally turned on when no reference is supplied.""")
	
	parser.add_argument("--resultmx",type=str,help="Specify an output image to store the result matrix. This is in the same format as the classification matrix. http://blake.bcm.edu/emanwiki/EMAN2/ClassmxFiles", default=None)
	
	parser.add_argument("--refinemultireftag", type=str, help="DO NOT USE THIS PARAMETER. It is passed on from e2spt_refinemulti.py if needed.", default='')

	parser.add_argument("--radius", type=float, help="""Hydrodynamic radius of the particle in Angstroms. 
													This will be used to automatically calculate the angular steps to use in search of the best alignment.
													Make sure the apix is correct on the particles' headers, sine the radius will be converted from Angstroms to pixels.
													Then, the fine angular step is equal to 360/(2*pi*radius), and the coarse angular step 4 times that""", default=0)
	parser.add_argument("--precision",type=float,default=1.0,help="""Precision in pixels to use
		when figuring out alignment parameters automatically using --radius. Precision 
		would be the number of pixels that the the edge of the specimen is moved (rotationally) during the 
		finest sampling, --falign. If precision is 1, then the precision of alignment will be that of 
		the sampling (apix of your images) times the --shrinkfine factor specified.""")
	
	parser.add_argument("--search", type=int,default=8,help=""""During COARSE alignment
		translational search in X, Y and Z, in pixels. Default=8.
		This WILL overwrite any search: provided through --align,
		EXCEPT if you provide --search=8, which is the default. In general, just avoid
		providing search twice (through here and through the aligner, --align). If you do,
		just be careful to make them consistent to minimize misinterpretation and error.""")
	
	parser.add_argument("--searchfine", type=int,default=2,help=""""During FINE alignment
		translational search in X, Y and Z, in pixels. Default=2.
		This WILL overwrite any search: provided through --falign,
		EXCEPT if you provide --searchfine=2, which is the default. In general, just avoid
		providing search twice (through here and through the fine aligner --falign). If you do,
		just be careful to make them consistent to minimize misinterpretation and error.""")
	
	parser.add_argument("--donotaverage",action="store_true", help="If e2spt_refinemulti.py is calling e2spt_classaverage.py, the latter need not average any particles, but rather only yield the alignment results.", default=False)
	
	parser.add_argument("--iter", type=int, help="The number of iterations to perform. Default is 1.", default=1, guitype='intbox', row=5, col=0, rowspan=1, colspan=1, nosharedb=True, mode='alignment,breaksym')
	parser.add_argument("--savesteps",action="store_true", help="If set, will save the average after each iteration to class_#.hdf. Each class in a separate file. Appends to existing files.",default=False, guitype='boolbox', row=4, col=0, rowspan=1, colspan=1, mode='alignment,breaksym')
	parser.add_argument("--saveali",action="store_true", help="If set, will save the aligned particle volumes in class_ptcl.hdf. Overwrites existing file.",default=False, guitype='boolbox', row=4, col=1, rowspan=1, colspan=1, mode='alignment,breaksym')
	parser.add_argument("--saveallalign",action="store_true", help="If set, will save the alignment parameters after each iteration",default=False, guitype='boolbox', row=4, col=2, rowspan=1, colspan=1, mode='alignment,breaksym')
	parser.add_argument("--sym", dest = "sym", default=None, help = "Symmetry to impose - choices are: c<n>, d<n>, h<n>, tet, oct, icos", guitype='symbox', row=9, col=1, rowspan=1, colspan=2, mode='alignment,breaksym')
	
	parser.add_argument("--mask",type=str,help="""Mask processor applied to particles before alignment. 
		Default is mask.sharp:outer_radius=-2. IF using --clipali, make sure to express outer mask radii as negative 
		pixels from the edge.""", returnNone=True, default="mask.sharp:outer_radius=-2", 
		guitype='comboparambox', choicelist='re_filter_list(dump_processors_list(),\'mask\')', 
		row=11, col=0, rowspan=1, colspan=3, mode='alignment,breaksym')
	
	parser.add_argument("--maskfile",type=str,default=None,help="""Mask file (3D IMAGE) applied to particles 
		before alignment. Must be in HDF format. Default is None.""")
	
	parser.add_argument("--normproc",type=str,help="""Normalization processor applied to 
		particles before alignment. Default is 'normalize.edgemean'. 
		If normalize.mask is used, results of the mask option will be passed in automatically. 
		If you want to turn this option off specify \'None\'""", default='normalize.edgemean')
	
	parser.add_argument("--threshold",type=str,default='',help="""A threshold applied to 
		the subvolumes after normalization. 
		For example, --threshold=threshold.belowtozero:minval=0 makes all negative pixels 
		equal 0, so that they do not contribute to the correlation score.""", guitype='comboparambox', choicelist='re_filter_list(dump_processors_list(),\'filter\')', row=10, col=0, rowspan=1, colspan=3, mode='alignment,breaksym')
	
	
	parser.add_argument("--preprocess",type=str,default='',help="Any processor (as in e2proc3d.py) to be applied to each volume prior to COARSE alignment. Not applied to aligned particles before averaging.", guitype='comboparambox', choicelist='re_filter_list(dump_processors_list(),\'filter\')', row=10, col=0, rowspan=1, colspan=3, mode='alignment,breaksym')
	parser.add_argument("--preprocessfine",type=str,default='',help="Any processor (as in e2proc3d.py) to be applied to each volume prior to FINE alignment. Not applied to aligned particles before averaging.")
	
	parser.add_argument("--lowpass",type=str,default='',help="A lowpass filtering processor (as in e2proc3d.py) to be applied to each volume prior to COARSE alignment. Not applied to aligned particles before averaging.", guitype='comboparambox', choicelist='re_filter_list(dump_processors_list(),\'filter\')', row=17, col=0, rowspan=1, colspan=3, mode='alignment,breaksym')
	parser.add_argument("--lowpassfine",type=str,default='',help="A lowpass filtering processor (as in e2proc3d.py) to be applied to each volume prior to FINE alignment. Not applied to aligned particles before averaging.")

	parser.add_argument("--highpass",type=str,default='',help="A highpass filtering processor (as in e2proc3d.py) to be applied to each volume prior to COARSE alignment. Not applied to aligned particles before averaging.", guitype='comboparambox', choicelist='re_filter_list(dump_processors_list(),\'filter\')', row=18, col=0, rowspan=1, colspan=3, mode='alignment,breaksym')
	parser.add_argument("--highpassfine",type=str,default='',help="A highpass filtering processor (as in e2proc3d.py) to be applied to each volume prior to FINE alignment. Not applied to aligned particles before averaging.")

	parser.add_argument("--shrink", type=int,default=1,help="Optionally shrink the input volumes by an integer amount for coarse alignment.", guitype='shrinkbox', row=5, col=1, rowspan=1, colspan=1, mode='alignment,breaksym')
	parser.add_argument("--shrinkfine", type=int,default=1,help="Optionally shrink the input volumes by an integer amount for refine alignment.", guitype='intbox', row=5, col=2, rowspan=1, colspan=1, mode='alignment')

	parser.add_argument("--clipali",type=int,default=0,help="""Boxsize to clip particles as part of preprocessing
		to speed up alignment. For example, the boxsize of the particles might be 100 pixels, but the particles are only 50 pixels 
		in diameter. Aliasing effects are not always as deleterious for all specimens, and sometimes 2x padding isn't necessary;
		still, there are some benefits from 'oversampling' the data during averaging; so you might still want an average of size
		2x, but perhaps particles in a box of 1.5x are sufficiently good for alignment. In this case, you would supply --clipali=75""")
	
	parser.add_argument("--postprocess",type=str,help="A processor to be applied to the FINAL volume after averaging the raw volumes in their FINAL orientations, after all iterations are done.",default=None, guitype='comboparambox', choicelist='re_filter_list(dump_processors_list(),\'filter\')', row=16, col=0, rowspan=1, colspan=3, mode='alignment,breaksym')
	
	parser.add_argument("--procfinelikecoarse",action='store_true',default=False,help="""
		If you supply this parameters, particles for fine alignment will be preprocessed
		identically to particles for coarse alignment by default.  
		If you supply this, but want specific parameters for preprocessing particles for 
		also supply: fine alignment, nd supply fine alignment parameters, such as 
		--lowpassfine, --highpassfine, etc; to preprocess the particles for FINE alignment 
		differently than for COARSE alignment.""")
	
	parser.add_argument("--npeakstorefine", type=int, help="The number of best coarse alignments to refine in search of the best final alignment. Default=4.", default=4, guitype='intbox', row=9, col=0, rowspan=1, colspan=1, nosharedb=True, mode='alignment,breaksym[1]')
	parser.add_argument("--align",type=str,help="""This is the aligner used to align particles 
		to the previous class average. Default is rotate_translate_3d:search=8:delta=12:dphi=12, 
			specify 'None' (with capital N) to disable.""", returnNone=True, default="rotate_translate_3d:search=8:delta=12:dphi=12", guitype='comboparambox', choicelist='re_filter_list(dump_aligners_list(),\'3d\')', row=12, col=0, rowspan=1, colspan=3, nosharedb=True, mode="alignment,breaksym['rotate_symmetry_3d']")
	parser.add_argument("--aligncmp",type=str,help="The comparator used for the --align aligner. Default is the internal tomographic ccc. Do not specify unless you need to use another specific aligner.",default="ccc.tomo", guitype='comboparambox',choicelist='re_filter_list(dump_cmps_list(),\'tomo\')', row=13, col=0, rowspan=1, colspan=3,mode="alignment,breaksym")
	
	parser.add_argument("--falign",type=str,help="""This is the second stage aligner used to fine-tune the first alignment. 
		Default is refine_3d_grid:delta=3:range=15:search=2, specify 'None' to disable.""", 
		default="refine_3d_grid:delta=3:range=15:search=2", returnNone=True, guitype='comboparambox', 
		choicelist='re_filter_list(dump_aligners_list(),\'refine.*3d\')', row=14, col=0, rowspan=1, 
		colspan=3, nosharedb=True, mode='alignment,breaksym[None]')
		
	parser.add_argument("--faligncmp",type=str,help="""The comparator used by the second stage aligner. 
		Default is the internal tomographic ccc""",default="ccc.tomo", guitype='comboparambox',
		choicelist='re_filter_list(dump_cmps_list(),\'tomo\')', row=15, col=0, rowspan=1, 
		colspan=3,mode="alignment,breaksym")		
		
	parser.add_argument("--averager",type=str,help="""The type of averager used to produce 
		the class average. Default=mean.tomo""",default="mean.tomo")
		
	parser.add_argument("--keep",type=float,default=1.0,help="""The fraction of particles to keep in each class.""", 
		guitype='floatbox', row=6, col=0, rowspan=1, colspan=1, mode='alignment,breaksym')
	
	parser.add_argument("--keepsig", action="store_true", help="""
		Causes the keep argument to be interpreted in standard deviations.""",
		default=False, guitype='boolbox', row=6, col=1, rowspan=1, colspan=1, mode='alignment,breaksym')

	parser.add_argument("--inixforms",type=str,help="directory containing a dict of transform to apply before reference generation", default="", guitype='dirbox', dirbasename='spt_|sptsym_', row=7, col=0,rowspan=1, colspan=2, nosharedb=True, mode='breaksym')
	
	parser.add_argument("--breaksym",action="store_true", default=False,help="""Break symmetry. Do not 
		apply symmetrization after averaging, even if searching the asymmetric unit provided 
		through --sym only for alignment. Default=False""", guitype='boolbox', row=7, col=2, rowspan=1, colspan=1, nosharedb=True, mode=',breaksym[True]')
	
	parser.add_argument("--groups",type=int,help="""This parameter will 
		split the data into a user defined number of groups. For purposes of gold-standard FSC
		computation later, select --group=2.""",default=0)
		
	parser.add_argument("--randomizewedge",action="store_true", help="This parameter is EXPERIMENTAL. It randomizes the position of the particles BEFORE alignment, to minimize missing wedge bias and artifacts during symmetric alignment where only a fraction of space is scanned", default=False)
	parser.add_argument("--savepreprocessed",action="store_true", help="Will save stacks of preprocessed particles (one for coarse alignment and one for fine alignment if preprocessing options are different).", default=False)
	
	#parser.add_argument("--nocenterofmass", default=False, action="store_true", help="""Disable Centering 
	#	of mass of the subtomogram every iteration.""", guitype='boolbox', row=6, col=2, rowspan=1, colspan=1, mode='alignment,breaksym')
	
	parser.add_argument("--autocenter",type=str, default='',help="""Autocenters each averaged pair 
		during initial average generation with --btref and --hacref. 
		Will also autocenter the average of all particles after each iteration of iterative 
		refinement. 
		Options are --autocenter=xform.centerofmass (self descriptive), or
		--autocenter=xform.centeracf, which applies auto-convolution on the average.
		Default=None.""")
	
	parser.add_argument("--autocentermask",type=str, default='',help="""Masking processor 
		to apply before autocentering. Default=None.
		See 'e2help.py processors -v 10' at the command line.""")
	
	parser.add_argument("--autocenterpreprocess",action='store_true', default=False,help="""This 
		will apply a highpass filter at a frequency of half the box size times the apix, 
		shrink by 2, and apply a low pass filter at half nyquist frequency to any computed
		average for autocentering purposes if --autocenter is provided. Default=False.""")
	
	parser.add_argument("--parallel",  help="Parallelism. See http://blake.bcm.edu/emanwiki/EMAN2/Parallel", default="thread:1", guitype='strbox', row=19, col=0, rowspan=1, colspan=3, mode='alignment,breaksym')
	
	#parser.add_argument("--automask",action="store_true",help="Applies a 3-D automask before centering. Can help with negative stain data, and other cases where centering is poor.")
	#parser.add_argument("--resample",action="store_true",help="If set, will perform bootstrap resampling on the particle data for use in making variance maps.",default=False)
	#parser.add_argument("--odd", default=False, help="Used by EMAN2 when running eotests. Includes only odd numbered particles in class averages.", action="store_true")
	#parser.add_argument("--even", default=False, help="Used by EMAN2 when running eotests. Includes only even numbered particles in class averages.", action="store_true")
	
	parser.add_argument("--ppid", type=int, help="Set the PID of the parent process, used for cross platform PPID",default=-1)
	parser.add_argument("--verbose", "-v", dest="verbose", action="store", metavar="n",type=int, default=0, help="verbose level [0-9], higner number means higher level of verboseness")


	parser.add_argument("--resume",type=str,default='',help="""tomo_fxorms.json file that contains alignment information for the particles in the set. 
															If the information is incomplete (i.e., there are less elements in the file than particles in the stack),
															on the first iteration the program will complete the file by working ONLY on particle indexes that are missing.
															For subsequent iterations, all the particles will be used.""")
															
	parser.add_argument("--hacref",type=int,default=0,help="""Size of the SUBSET 
		of particles to use to build an initial reference by calling e2spt_hac.py
		which does Hierarchical Ascendant Classification (HAC) or 'all vs all' alignments.""") 
		
	parser.add_argument("--ssaref",type=int,default=0,help="""Size of the SUBSET
		of particles to use to build an initial reference by calling e2symsearch3d.py,
		which does self-symmetry alignments. You must provide --sym different
		than c1 for this to make any sense.""")
		
	parser.add_argument("--btref",type=int,default=0,help="""Size of the SUBSET
		of particles to use to build an initial reference by calling e2spt_binarytree.py.
		By default, the largest power of two smaller than the number of particles in --input
		will be used.
		For example, if you supply a stack with 150 subtomograms, the program will
		automatically select 128 as the limit to use because it's the largest power of 2 that is
		smaller than 150. But if you provide, say --btref=100, then the number of particles
		used will be 64, because it's the largest power of 2 that is still smaller than 100.""")
	
	parser.add_argument("--plotccc", action='store_true', help="""Turn this option on to generate
		a plot of the ccc scores during each iteration.
		Running on a cluster or via ssh remotely might not support plotting.""",default=False)

	parser.add_argument("--subset",type=int,default=0,help="""Refine only this substet
		of particles from the stack provided through --input""")
	
	(options, args) = parser.parse_args()
		
	
	'''
	Get rootpath to provide absoulute paths to files.
	Make the directory where to create the database where the results will be stored, if --resume is not provided.
	'''
	
	rootpath = os.getcwd()
	#print "I am trying to open from here", rootpath
	#print "And the path is", options.path

	if not options.resume:
		options = sptmakepath(options,'spt')	
	else:
		if rootpath not in options.resume:
			options.resume = rootpath + '/' + options.resume
	
		if not options.path:
			print """\nERROR: If you provide --resume, you need to specify which working 
			directory needs to be resumed. Provide it through --path"""			
			sys.exit()

	abspath= rootpath + '/' + options.path
	#print "\nThus the abs path could be", abspath
	
	
	if not options.input:
		parser.print_help()
		exit(0)
	elif options.subset:
		subsetStack = options.path + '/subset' + str( options.subset ).zfill( len( str( options.subset))) + '.hdf' 
		print "\nSubset to be written to", subsetStack
		
		subsetcmd = 'e2proc3d.py ' + options.input + ' ' + subsetStack + ' --first=0 --last=' + str(options.subset-1) 
		print "Subset cmd is", subsetcmd
		
		p=subprocess.Popen( subsetcmd, shell=True,stdout=subprocess.PIPE, stderr=subprocess.PIPE )
		text=p.communicate()	
		p.stdout.close()
		
		options.input = subsetStack
		
	if options.align:
		#print "There's options.align", options.align
		if options.sym and options.sym is not 'c1' and options.sym is not 'C1' and 'sym' not in options.align and 'grid' not in options.align:
			if 'rotate_translate_3d' in options.align or 'rotate_symmetry_3d' in options.align:
				options.align += ':sym=' + str( options.sym )
			#print "And there's sym", options.sym
			
		if 'search' not in options.align:
			if 'rotate_translate_3d' in options.align:	
				options.align += ':search=' + str( options.search )
			
		elif 'rotate_translate_3d' in options.align:
			searchA = options.align.split('search=')[-1].split(':')[0]
			searchdefault = 8
			
			if options.search != searchdefault:
						
				prefix = options.align.split('search=')[0]
				trail = options.align.split('search=')[-1].split(':')[-1]
			
				options.align =  prefix + 'search=' + str(options.search)
				if len(trail) > 2 and '=' in trail:
					options.align += ':' + trail 
			
				print """\nWARNING: --search is different from search= provided through
				--align or its default value of 8. There's no need to specify both, but 
				if you did, --search takes precedence :-) ."""
				#sys.exit()
			elif options.search == searchdefault:
				options.search = searchA
			

		if "rotate_translate_3d_grid" in options.align:
			if "alt0" and "alt1" in options.align:
				alt0 = int(options.align.split('alt0')[-1].split(':')[0].replace('=',''))	
				alt1 = int(options.align.split('alt1')[-1].split(':')[0].replace('=',''))
				
				print "alt0 and alt1 are", alt0,alt1, type(alt0), type(alt1)
				print alt1-alt0 == 0
				#sys.exit()
				
				if alt1-alt0 == 0:
					print """\nERROR: alt0 and alt1 cannot be equal for rotate_translate_3d_grid.
					If you want to inactivate searches in this angle, provide a alt0 and alt1
					such that alt1-alt0 is NOT ZERO, and provide a step size for dalt that is larger
					than this difference. For example: 
					alt0=0:alt1=1:dalt=2."""
					sys.exit()
					
			if "phi0" and "phi1" in options.align:
				phi0 = int(options.align.split('phi0')[-1].split(':')[0].replace('=',''))	
				phi1 = int(options.align.split('phi1')[-1].split(':')[0].replace('=',''))
				
				print "phi0 and phi1 are", phi0,phi1, type(phi0), type(phi1)
				print phi1-phi0 == 0
				#sys.exit()
				
				if phi1-phi0 == 0:
					print """\nERROR: phi0 and phi1 cannot be equal for rotate_translate_3d_grid.
					If you want to inactivate searches in this angle, provide a phi0 and phi1
					such that phi1-phi0 is NOT ZERO, and provide a step size for dphi that is larger
					than this difference. For example: 
					phi0=0:phi1=1:dphi=2."""
					sys.exit()
					
			if "az0" and "az1" in options.align:
				az0 = int(options.align.split('az0')[-1].split(':')[0].replace('=',''))	
				az1 = int(options.align.split('az1')[-1].split(':')[0].replace('=',''))
				
				print "az0 and az1 are", az0,az1, type(az0), type(az1)
				print az1-az0 == 0
				#sys.exit()
				
				if az1-az0 == 0:
					print """\nERROR: az0 and az1 cannot be equal for rotate_translate_3d_grid.
					If you want to inactivate searches in this angle, provide a az0 and az1
					such that az1-az0 is NOT ZERO, and provide a step size for daz that is larger
					than this difference. For example: 
					az0=0:az1=1:daz=2."""
					sys.exit()
			
	#print "\n\nBefore adding search, options.falign is", options.falign, type(options.falign)	
	if options.falign and options.falign != None and options.falign != 'None' and options.falign != 'none':
		if 'search' not in options.falign and 'refine_3d_grid' in options.falign:		
			options.falign += ':search=' + str( options.searchfine )
			
		else:
			searchF = options.falign.split('search=')[-1].split(':')[0]
			searchfinedefault = 2
			
			if options.searchfine != searchfinedefault:
						
				prefix = options.falign.split('search=')[0]
				trail = options.falign.split('search=')[-1].split(':')[-1]
				
				options.falign =  prefix + 'search=' + str(options.searchfine)
				
				if len(trail) > 2 and '=' in trail:
				
					options.falign += ':' + trail 
			
				print """\nWARNING: --searchfine is different from search= provided through
				--falign or its default value of 2. There's no need to specify both, but 
				if you did, --searchfine takes precedence :-) ."""
				#sys.exit()
			
			elif options.searchfine == searchfinedefault:
				options.searchfine = searchF	
	
	if options.radius and float(options.radius) > 0.0:
		#print "(e2spt_classaverage.py)(main) before calling calcAliStep, options.input is", options.input
		options = calcAliStep(options)
	
	
	'''
	Parse parameters
	'''
	
	options = sptOptionsParser( options )

	if options.resultmx: 
		print "Sorry, resultmx not implemented yet"
	
	if options.resultmx != None: 
		options.storebad = True
			
	if options.shrink < options.shrinkfine:
		options.shrink = options.shrinkfine
		print "It makes no sense for shrinkfine to be larger than shrink; therefore, shrink will be made to match shrinkfine"
					
	hdr = EMData(options.input,0,True)
	nx = hdr["nx"]
	ny = hdr["ny"]
	nz = hdr["nz"]
	if nx!=ny or ny!=nz :
		print "ERROR, input volumes are not cubes"
		sys.exit(1)
	
	if options.ref:
		hdr = EMData(options.ref,0,True)
		if hdr["nx"]!=nx or hdr["ny"]!=ny or hdr["nz"]!=nz : 
			print "Error, ref volume not same size as input volumes"
			sys.exit(1)
	
	if not options.donotaverage:		
		if '.hdf' not in options.output:					
			print "Error in output name. Format must be '.hdf'; make sure you didn't mistake a comma for a dot"
			sys.exit(1)
		
	logger = E2init(sys.argv, options.ppid)
	
	'''
	Store parameters in parameters.txt file inside --path
	'''
	cmdwp = writeParameters(options,'e2spt_classaverage.py', 'sptclassavg')
	
	
	try: 
		classmx = EMData.read_images(options.classmx)		# we keep the entire classification matrix in memory, since we need to update it in most cases
		#ncls = int(classmx[0]["maximum"])
		ncls = int(classmx[0]['nx'])
	except:
		ncls=1
		#if options.resultmx!=None :
			#print "resultmx can only be specified in conjunction with a valid classmx input."
			#sys.exit(1)

	nptcl=EMUtil.get_image_count(options.input)
	
	
	if options.savepreprocessed:
		dummy = EMData(8,8,8)
		dummy.to_one()
		
		preprocnameCoarse = options.path + '/' + options.input.replace('.hdf','_preprocCoarse.hdf')
		preprocnameFine = options.path + '/' + options.input.replace('.hdf','_preprocFine.hdf')

		for i in range(nptcl):
			dummy.write_image( preprocnameCoarse ,i)
			
			if options.falign and options.falign != 'None' and options.falign != 'none':
				dummy.write_image( preprocnameFine ,i)
		
				
	if options.classmx and options.groups:
		print """ERROR: --groups is used to separate the data arbitrarily into classes.
				It should not be provided if you supply --classmx, and vice versa."""
		sys.exit(1)
		
	if nptcl<1 : 
		print "ERROR : at least 1 particle required in input stack"
		sys.exit(1)
		
	if nptcl==1:
		if options.iter>1 :
			print "Error: makes no sense to have iter>1 with one particle"
			sys.exit(1)
		
		if options.keepsig or options.keep!=1.0 :
			print "Error: do not use --keepsig with one particle, also keep should be 1.0 if specified"
			sys.exit(1)

	'''
	Initialize parallelism if being used
	'''
	
	if options.parallel :
	
		if options.parallel == 'none' or options.parallel == 'None' or options.parallel == 'NONE':
			options.parallel = ''
			etc = ''
		
		else:
			print "\n\n(e2spt_classaverage.py) INITIALIZING PARALLELISM!"
			print "\n\n"
			from EMAN2PAR import EMTaskCustomer
			etc=EMTaskCustomer(options.parallel)
			pclist=[options.input]
		
			if options.ref: 
				pclist.append(options.ref)
			etc.precache(pclist)
	else:
		etc=''

	if options.inixforms: 
		preOrientationsDict = js_open_dict(options.inixforms)
		
	resumeDict = {}
	actualNums=[]
	if options.resume: 
		print "The resume dict to open is", options.resume
		resumeDict = js_open_dict(options.resume)
		
		print "Resume dict is", resumeDict
		for key in resumeDict.keys():
			print "\n\nKKKKKKey is", key
			
			keyint = int ( key.split('_')[-1] )
			print "\n\nkeyint is", keyint
			
			actualNums.append( keyint )
		#actualNums = [int( key.split('_')[-1] ) for key in resumeDict ]
		
		print "ActualNums is", actualNums
		actualNums = set(actualNums)
		print "Which converted into set is", actualNums
		
		resumeDict.close()
	
	
	
				
	groupsize = nptcl
	ngroups = options.groups
	if not options.groups:
		ngroups=1
	
	classmxFile = options.path + '/classmx_' + str( 0 ).zfill( len (str (options.iter))) + '.hdf'
	
	if options.classmx:
		classmxFile = options.classmx
	else:
		options.classmx = classmxFile
	
	classmxScores = EMData(ngroups,nptcl)
	classmxWeights = EMData(ngroups,nptcl)
	classmxXs = EMData(ngroups,nptcl)
	classmxYs = EMData(ngroups,nptcl)
	classmxZs = EMData(ngroups,nptcl)
	classmxAzs = EMData(ngroups,nptcl)
	classmxAlts = EMData(ngroups,nptcl)
	classmxPhis = EMData(ngroups,nptcl)
	classmxScales = EMData(ngroups,nptcl)

	classmxScores.to_zero()
	classmxWeights.to_one() 
	classmxXs.to_zero()
	classmxYs.to_zero()
	classmxZs.to_zero()
	classmxAzs.to_zero()
	classmxAlts.to_zero()
	classmxPhis.to_zero()
	classmxScales.to_one()

	if int(options.groups) > 1:
		ncls = ngroups
		
		groupsize = int( int(nptcl)/int(options.groups) )
	
		if options.verbose > 3:
			print "(e2spt_classaverage.py) (main) options.groups is", options.groups
			print "(e2spt_classaverage.py) (main) And groupsize therefore is", groupsize
	
		for i in range(options.groups):
			print "\nIterating over n groups; i is", i
					
			bottom_range = i * groupsize
			top_range = (i+1) * groupsize		#Since e2proc3d.py includes the top range
												#for a set of 16 particles, for example
												#the top range would be index 15, becuase
												#numeration starts at 0. Therefore, you need to
												#subtract 1 to "top_range" if separating the particles
												#using e2proc3d.py. Not the case here though.
			if i == options.groups - 1:
				top_range = nptcl
			print "\nbottom and top ranges are", bottom_range, top_range
		
				
			for j in xrange(bottom_range, top_range):
				classmxScores.set_value_at(i,j,float(1))	#If a particle belongs to a class
															#It will have a non-zero score for
															#that class. Be it 1, for now.
															#This will change later, after alignment.
	classmxScores.write_image(classmxFile,0)
	classmxWeights.write_image(classmxFile,1)
	classmxXs.write_image(classmxFile,2)
	classmxYs.write_image(classmxFile,3)
	classmxZs.write_image(classmxFile,4)
	classmxAzs.write_image(classmxFile,5)
	classmxAlts.write_image(classmxFile,6)
	classmxPhis.write_image(classmxFile,7)	
	classmxScales.write_image(classmxFile,8)
	
		
		
	#divisioncmd = 'e2proc3d.py ' + options.input + ' ' + groupStack + ' --append --first=' + str(bottom_range) + ' --last=' + str(top_range)
				
	'''		
	This is where the actual class-averaging process begins.
	Iterating over all the classes, 'ic'.
	'''	
	
	
	originalOutput = options.output
	
	for ic in range(int(ncls)):
		
		
		
		
		
		
		classize=nptcl
		if ncls==1: 
			ptclnums=range(nptcl)						# Start with a list of particle numbers in this class
		elif ncls >1:
			classmx = EMData.read_images(options.classmx)
			print "The classmx file to read is", options.classmx
			print "Therefore, the classmx before classmx_ptcls, type is", type (classmx)
			
			options.output = originalOutput.replace('.hdf', '_' + str(ic).zfill( len (str (ncls))) + '.hdf')
			
			#ptclnums=classmx_ptcls(classmx,ic)			# This gets the list from the classmx
			
			ptclnums=[]
			scoresImg = classmx[0]
			for i in range(scoresImg['ny']):
				score = scoresImg.get_value_at(ic,i)
				if score:
					ptclnums.append(i)
			
			if ic == 0:
				classize=len(ptclnums)
		
		if options.verbose: 
			print "###### Processing class %d(%d)/%d"%(ic+1,ic,ncls)
			print "Particle numbers for this class are", ptclnums
		
		'''
		Getting reference either by reading from disk or bootstrapping
		'''
		if options.ref: 
			#ref = EMData(options.ref,ic)
			ref = EMData(options.ref,0)
			
			print "\n\nREAD reference image and values are", ref, ref['minimum'],ref['maximum'],ref['sigma'],ref['mean']
			
			if not ref['maximum'] and not ref['minimum']:
				print "Error. Empty reference."
				sys.exit()
			
			#sys.exit()
			
		elif options.hacref:
			elements = cmdwp.split(' ')
			
			hacelements = []
			for ele in elements:
				if '--output' not in ele and 'input' not in ele and 'ref' not in ele and '--path' not in ele and 'keep' not in ele and 'iter' not in ele:
					hacelements.append(ele)
			
			niterhac = options.hacref-1
					
			subsetForHacRef = 'subsetForHacRef.hdf'
			subsetCmd = 'e2proc3d.py ' + options.input + ' ' + subsetForHacRef + ' --first=0 --last=' + str( options.hacref -1 ) 
			
			print "\nCommand to extract subset for hacref is", subsetCmd
			
			p=subprocess.Popen( subsetCmd, shell=True,stdout=subprocess.PIPE, stderr=subprocess.PIPE)
			text=p.communicate()	
			p.stdout.close()
			
			cmdhac = ' '.join(hacelements)
			cmdhac=cmdhac.replace('e2spt_classaverage','e2spt_hac')
			cmdhac+=' --path=hacref'
			cmdhac+=' --iter='+str(niterhac)
			cmdhac+=' --input='+subsetForHacRef
			
			
			cmdhac+= ' && mv hacref ' + options.path + '/' + ' && mv ' + subsetForHacRef + ' ' + options.path
			
			if options.verbose:
				print "\nCommand to generate hacref is", cmdhac
	
			p=subprocess.Popen( cmdhac, shell=True,stdout=subprocess.PIPE, stderr=subprocess.PIPE)
			text=p.communicate()	
			p.stdout.close()
			
			#options.ref = 'hacref/finalAvg.hdf'
			ref = EMData(options.path +'/hacref/finalAvg.hdf',0)
			
			
			#cmdhac.replace(
			#pass
		
		elif options.ssaref:
			print """\nSelf-symmetry alignment not implemented yet.
				You can manually run e2symsearch3d.py."""
			
			if options.sym == 'c1' or options.sym == 'C1':
				print """\nERROR: You must provide at least c2 or higher symmetry to use
				--ssaref"""
			sys.exit(1)
				
		elif not options.hacref and not options.ssaref:
			nptclForRef = len(ptclnums)
			
			from e2spt_binarytree import binaryTreeRef
			
			nseed=2**int(floor(log(len(ptclnums),2)))
			
			if options.btref:
				nseed=2**int(floor(log( options.btref, 2 )))			
			
			ref = binaryTreeRef(options,nptclForRef,nseed,ic,etc)
			
			if options.savesteps:
				refname = options.path + '/class_' + str(ic).zfill( len( str(ic) )) + '.hdf'
			
				ref.write_image(refname,-1)
		
		'''
		Now we iteratively refine a single class
		'''
		#resNum = 0
		resumeDict = {}
		for it in range(options.iter):
			# In 2-D class-averaging, each alignment is fast, so we send each node a class-average to make
			# in 3-D each alignment is very slow, so we use a single ptcl->ref alignment as a task
			
			classmxFile = options.path + '/classmx_' + str( it ).zfill( len (str (options.iter))) + '.hdf'

			tasks=[]
			results=[]
				
			'''
			Define and open the .json dictionaries where alignment and score values will be stored, for each iteration,
			and for each reference if using multiple model refinement
			'''
			jsAliParamsPath = abspath + '/tomo_xforms.json'
			
			#if options.refinemultireftag:
			#	jsAliParamsPath = jsAliParamsPath.replace('.json','_ref' + str(options.refinemultireftag) + '.json')
			
			if not options.refinemultireftag:
				jsAliParamsPath = jsAliParamsPath.replace('.json', '_' + str(it).zfill( len(str(options.iter))) + '.json')
			
			print "(e2spt_classaverage.py) This is the .json file to write", jsAliParamsPath

			jsA = js_open_dict(jsAliParamsPath) #Write particle orientations to json database.
			
			
			if options.clipali:
				
				#sys.exit()
			
				sx = ref['nx']
				sy = ref['ny']
				sz = ref['nz']
		
				xc = sx/2
				yc = sy/2
				zc = sz/2
		
				newsize = options.clipali
		
				ref['origin_x'] = 0
				ref['origin_y'] = 0
				ref['origin_z'] = 0
				
				print "\nRef BEFORE clip ali is", ref, ref['nx'], ref['minimum'],ref['maximum'],ref['sigma'],ref['mean']
		
			
				r=Region( (2*xc - newsize)/2, (2*yc - newsize)/2, (2*zc - newsize)/2, newsize , newsize , newsize)
				
				
				ref.clip_inplace( r )
			
				print "\n\n\nRef AFTER clip ali is", ref, ref['nx'], ref['minimum'],ref['maximum'], ref['sigma'],ref['mean']
				if not ref['minimum'] and not ref['maximum']:
					print "ERROR: emtpy ref after clip ali, region", r
					print "sizes", ref['nx']
					sys.exit()
			
			
			
			'''
			Code to 'resume' crashed jobs
			'''
			if options.resume and actualNums:
				resumeDict = js_open_dict(options.resume)
				#resNum += 1
					
			for ptclnum in ptclnums:
	
				if actualNums and ptclnum in actualNums:
					print """Skipping this particle because you provided --resume and the alignment info for this particle is aready present.
					Info for particle loaded into results""", ptclnum
					
					tomoID = "tomo_" + str(ptclnum).zfill( len(str( len(ptclnums) )) )
					
					if tomoID not in resumeDict.keys():
						print "ERROR: This key is not in the file provided for --resume", tomoID
						sys.exit() 
					
			
					if len(resumeDict.keys()) > 0:
					 	keys = resumeDict.keys()
					 	
					 	for key in keys:
					 		if type(resumeDict[key]) is not list:					 
								print """ERROR: Your tomo_xforms.json file seems to be incomplete. The value for the particle key is a Transform(), but should be a list.
								The file should contain a dictionary where there's a 'key' for each particle, containing the word 'tomo_' followed by the particle's index 
								(with as many digits as there are orders of magnitude in the set; for example
								the first particle in a set of 10 would be 'tomo_0', but in a set of 10 to 100 it would be 'tomo_00', and in a set of 101 to 1000
								it would be 'tomo_000'), and the 'value' of each key would be a list with two elements, [ Transform(), score ], where Transform
								contains the alignment parameters between a particle and the reference, and score the cross correlation score for that alignment.""" 
								sys.exit()
							
					results.append( [ {'xform.align3d': resumeDict[tomoID][0] , 'score':resumeDict[tomoID][1] } ] )
					
				if options.inixforms:
					tomoID = "tomo_" + str(ptclnum).zfill( len(str( len(ptclnums) )) )
					transform = preOrientationsDict[tomoID][0]
					
					print transform
					print "Of type", type(transform)
					
				else:
					transform = None
				
				if options.parallel:
					task=Align3DTask(ref,["cache",options.input,ptclnum],ptclnum,"Ptcl %d in iter %d"%(ptclnum,it),options,transform,it)
					tasks.append(task)
				else:
					#print "No parallelism specified"
					result=align3Dfunc(ref,["cache",options.input,ptclnum],ptclnum,"Ptcl %d in iter %d"%(ptclnum,it),options,transform,it)
					
					results.append(result['final'])
			
			# start the alignments running
			if options.parallel:
				tids=etc.send_tasks(tasks)
				if options.verbose: 
					print "%d tasks queued in class %d iteration %d"%(len(tids),ic,it) 

				"""Wait for alignments to finish and get results"""
				#results=get_results(etc,tids,options.verbose,jsA,len(ptclnums),1)
				results=get_results(etc,tids,options.verbose,jsA, nptcl ,1)
			
			if options.verbose > 2: 
				print "Results:" 
				pprint(results)
						
			
			if not options.donotaverage:					
				#ref = make_average(options,ic,options.input,options.path,results,options.averager,options.saveali,options.saveallalign,options.keep,options.keepsig,options.sym,options.groups,options.breaksym,options.nocenterofmass,options.verbose,it)
				ref = makeAverage(options,ic,results,it)

			
			
			if options.savesteps and not options.donotaverage:
				refname = options.path + '/class_' + str(ic).zfill( len( str(ic) )) + '.hdf'
				ref['xform.align3d']=Transform()
				ref['origin_x'] = 0
				ref['origin_y'] = 0
				ref['origin_z'] = 0
				
				ref.write_image(refname,it)
				
				print "\n\nFor the final avg going into class_x.hdf, ali params are", ref['xform.align3d']
				
				if options.postprocess:
					ppref = ref.copy()
					maskPP = "mask.sharp:outer_radius=-2"
					maskPP=parsemodopt(maskPP)
	
					ppref = postprocess(ppref,maskPP,options.normproc,options.postprocess)

					refnamePP = refname.replace('.hdf', '_postproc.hdf')
					
					#ppref.write_image("%s/class_%02d.hdf"%(options.path,ic),it)
					ppref.write_image(refnamePP,it)
			
				
		
			jsA.close()
		
			
			classScoresList = [] 
			
			iii=0
			for r in results:
				if r and r[0]:	
					score = r[0]['score']
					classmxScores.set_value_at(ic,iii,score)
					
					#posscore = math.fabs(score)
					classScoresList.append(score)
					#print "\n\n\n\n\n\n\n\nThe appended positive score is", posscore
					
					weight=1.0
					classmxWeights.set_value_at(ic,iii,weight)
					
					t = r[0]['xform.align3d']
					trans=t.get_trans()
					print "\n\n\nTranslations were", trans
					print "Therefre the transform was", t
					rots=t.get_rotation()
					
					tx=trans[0]
					print "Translation in x was", tx
					classmxXs.set_value_at(ic,iii,tx)
					
					ty=trans[1]
					print "Translation in y was", ty
					classmxYs.set_value_at(ic,iii,ty)
					
					tz=trans[2]
					print "Translation in z was", tz
					classmxZs.set_value_at(ic,iii,tz)
					
					az=rots['az']
					classmxAzs.set_value_at(ic,iii,az)
					
					alt=rots['alt']
					classmxAlts.set_value_at(ic,iii,alt)
					
					phi=rots['phi']
					classmxPhis.set_value_at(ic,iii,phi)
					
					scale=1.0
					classmxScales.set_value_at(ic,iii,scale)
				iii+=1
										
			classmxScores.write_image(classmxFile,0)
			classmxWeights.write_image(classmxFile,1)
			classmxXs.write_image(classmxFile,2)
			classmxYs.write_image(classmxFile,3)
			classmxZs.write_image(classmxFile,4)
			classmxAzs.write_image(classmxFile,5)
			classmxAlts.write_image(classmxFile,6)
			classmxPhis.write_image(classmxFile,7)	
			classmxScales.write_image(classmxFile,8)
		
		
		if options.plotccc:
			#classScoresList.reverse()
			maxY = max(classScoresList) + 1
			
			plotX = range( len(classScoresList) )
			maxX = max(plotX) + 1
			
			plotName = 'spt_cccs.png'
			
			if int( ncls ) > 1:
				plotName.replace('.png', '_' + str(ic).zfill( len (str (ncls))) + '.png')
			
			from e2spt_hac import textwriter
			
			txtname = plotName.replace('.png','.txt')
			textwriter(classScoresList,options,txtname)
			
			from e2spt_hac import plotter
			plotter(plotX, classScoresList, options, plotName, maxX, maxY)
		
		if options.verbose: 
			print "Preparing final average"
		
		if type(ref) is list:
			print "You supplied a reference file that has more than one reference in it! EXITING."
			sys.exit()
		
		elif not options.donotaverage:									
			ref['origin_x']=0
			ref['origin_y']=0		#The origin needs to be reset to ZERO to avoid display issues in Chimera
			ref['origin_z']=0
			ref['xform.align3d'] = Transform()
			
			outdir = options.path
			#if 'bdb:' in options.path:
			#	outdir = options.path.replace('bdb:','')
			
			if outdir[-1] != '/':
				outdir += '/'
			
			finaloutput = outdir + options.output

			#print "\n\n\n\n\n\nBefore writing out the average, its ali params are", ref['xform.align3d']
			
			if options.verbose:
				print "The file to write the final output to is", finaloutput
			
			#print "\n\n\n\n\n\nBefore writing out the average, its ali params are", ref['xform.align3d']
			
			ref.write_image(finaloutput,0)
			
			if options.resume and actualNums:
				resumeDict.close()
			
			actualNums = [] 		#Reset this so that when --resume is provided the incomplete jason file is 'fixed' considering the info in actualNums only once

		ic+=1	
		
	if options.inixforms: 
		preOrientationsDict.close()
	print "Will end logger"	
	E2end(logger)
	
	print "logger ended"
	sys.stdout.flush()
	
	return


def sptOptionsParser( options ):
	try:
		if options.align:
			#print "(e2spt_classaverage.py) --align to parse is", options.align
			options.align=parsemodopt(options.align)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --align not provided"
		
	try:
		if options.falign and options.falign != None and options.falign != 'None' and options.falign != 'none': 
			options.falign=parsemodopt(options.falign)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --falign not provided"
	
	try:
		if options.aligncmp: 
			options.aligncmp=parsemodopt(options.aligncmp)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --aligncmp not provided"
	
	try:	
		if options.faligncmp: 
			options.faligncmp=parsemodopt(options.faligncmp)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --faligncmp not provided"
		
	try:
		if options.averager: 
			options.averager=parsemodopt(options.averager)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --averager not provided"
		
	try:
		if options.autocenter:
			options.autocenter=parsemodopt(options.autocenter)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --autocenter not provided"
		
	try:
		if options.autocentermask:
			options.autocentermask=parsemodopt(options.autocentermask)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --autocentermask not provided"
	
	try:
		if options.normproc and options.normproc != 'None' and options.normproc != 'none':
			options.normproc=parsemodopt(options.normproc)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --normproc not provided"
	
	try:
		if options.mask and options.mask != 'None' and options.mask != 'none':
			#print "parsing mask", sys.exit()
			options.mask=parsemodopt(options.mask)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --mask not provided"
	
	try:	
		if options.preprocess and options.preprocess != 'None' and options.preprocess != 'none': 
			options.preprocess=parsemodopt(options.preprocess)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --preprocess not provided"
	
	try:	
		if options.threshold and options.threshold != 'None' and options.threshold != 'none': 
			options.threshold=parsemodopt(options.threshold)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --threshold not provided"
	
	try:
		if options.preprocessfine and options.preprocessfine != 'None' and options.preprocessfine != 'none': 
			options.preprocessfine=parsemodopt(options.preprocessfine)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --preprocessfine not provided"
	
	try:	
		if options.lowpass and options.lowpass != 'None' and options.lowpass != 'none': 
			options.lowpass=parsemodopt(options.lowpass)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --lowpass not provided"
	
	try:
		if options.lowpassfine and options.lowpassfine != 'None' and options.lowpassfine != 'none': 
			options.lowpassfine=parsemodopt(options.lowpassfine)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --lowpassfine not provided"
	
	try:
		if options.highpass and options.highpass != 'None' and options.highpass != 'none': 
			options.highpass=parsemodopt(options.highpass)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --highpass not provided"
	
	try:
		if options.highpassfine and options.highpassfine != 'None' and options.highpassfine != 'none': 
			options.highpassfine=parsemodopt(options.highpassfine)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --highpassfine not provided"
	
	
	try:
		if options.postprocess and options.postprocess != 'None' and options.postprocess != 'none': 
			options.postprocess=parsemodopt(options.postprocess)
	except:
		if options.verbose > 9:
			print "\nWARNING (might not be relevant): --postprocess not provided"
		
	return options


'''
Function to write the parameters used for every run of the program to parameters.txt inside the path specified by --path.
*** Imported by many e2spt programs ***
'''
def writeParameters( options, program, tag ):
	print "Tag received in writeParameters is", tag

	names = dir(options)
	
	cmd = program
	lines = []
	now = datetime.datetime.now()
	lines.append(str(now)+'\n')
	
	#print "\nnames are", names
	optionscopy = options
	
	if options.search == 0 or options.search == 0.0:
		options.search = '0'
	if options.searchfine == 0 or options.searchfine == 0.0:
		options.searchfine = '0'
	
	#print "mask in write parameters is", optionscopy.mask, type(optionscopy.mask)
	for name in names:
				
		if getattr(options,name) and "__" not in name and "_" not in name:
		#if "__" not in name and "_" not in name:	
	
			#if "__" not in name and "_" not in name and str(getattr(options,name)) and 'path' not in name and str(getattr(options,name)) != 'False' and str(getattr(options,name)) != 'True' and str(getattr(options,name)) != 'None':			
			line = name + '=' + str(getattr(optionscopy,name))
					
			lines.append(line+'\n')
			
			if str(getattr(optionscopy,name)) != 'True' and str(getattr(optionscopy,name)) != 'False' and str(getattr(optionscopy,name)) != '':
			
				if name != 'parallel':
					if "{" in str(getattr(optionscopy,name)) or "}" in  str(getattr(optionscopy,name)) or ")" in  str(getattr(optionscopy,name)) or ")"  in str(getattr(optionscopy,name)): 
						cmd += ' --' + name + '=' + str(getattr(optionscopy,name)).replace(':','=').replace('(','').replace(')','').replace('{','').replace('}','').replace(',',':').replace(' ','').replace("'",'')
					else:
						cmd += ' --' + name + '=' + str(getattr(optionscopy,name))
						
				else:
					cmd += ' --' + name + '=' + str(getattr(optionscopy,name))
			
			elif str(getattr(optionscopy,name)) == 'True' or str(getattr(optionscopy,name)) == 'False':
				cmd += ' --' + name
	
	parmFile = 'parameters_' + tag + '.txt'
	lines.append('\n'+cmd+'\n')
	f=open(optionscopy.path + '/' + parmFile,'w')
	f.writelines(lines)
	f.close()
	
	return cmd


def calcAliStep(options):

	print "\n\n(e2spt_classaverage.py)(calcAliStep) options.radius is", options.radius
	print "(e2spt_classaverage.py)(calcAliStep) options.input is", options.input

	hdr = EMData( options.input,0,True )
	apix = float( hdr['apix_x'] )
	capix = apix
	fapix =apix
	
	#if options.shrinkfine and float(options.shrinkfine) > 1.0:
	#	apix = 2*apix
	
	factor = factorc = factorf = factorRelative = 1.0
	
	#radPix = radPixC = radPixF = options.radius
	
	if options.shrink and float( options.shrink ) > 1.0:
		print "options.shrink is > 1, see:", options.shrink
		factorc = options.shrink
		capix =  apix*factor
	
	if options.shrinkfine  and float( options.shrinkfine ) > 1.0:
		factorf = options.shrinkfine
		print "options.shrinkfine > 1, see:", options.shrinkfine
		fapix = apix*factorf
	
	#if factorc > 1.0 and factorf > 1.0:										#The relative shrinking factor doesn't really matter
	#	factorRelative = factorc / factorf
	
	print "\n\n\n\nAAAAAAAAAAA\nApix is", apix
	print "\n\n\n\nAAAAAAAAAAA\n"
	
	radPixC = options.radius / capix
	radPixF = options.radius / fapix

	coarseStep1pix =  360.0/(2.0*math.pi*radPixC)
	#coarseStep1pixRounded = math.floor(coarseStep1pix*100.00)/100.00
	
	if options.precision > 1.0:
		coarseStep1pix *= options.precision
	
	fineStep = 360.0/(2.0*math.pi*radPixF)
	if options.precision > 1.0:
		fineStep *= options.precision
	
	fineStepRounded = math.floor(fineStep*100.00)/100.00					#Round fine step DOWN to scan slightly more finally than theoretically needed
	
	rango = 2.0 * fineStep													#Alignment goes from -range (rango) to +range
	#rango = coarseStep / 2.0									
	rangoRounded = math.ceil(rango*100.00)/100.00							#Round the range in fine alignments UP, to cover a slightly larger area than theoretically needed
	
	angularDistance = 2.0*rango												#This is the angular distance between points generated by the sphere aligner for coarse alignment
	angularDistanceRounded = math.floor(angularDistance*100.00)/100.00		#Round angular distance between coarse points down, to sample more tightly
	
	coarseStep = angularDistanceRounded / 2.25								#The 2.25 factor is approximate. The angular distance A between two rotations R1=a1,b1,c1 and R2=a2,b2,c2 
																			#where r1=a1=b1=c1 and r2=a2=b2=c2, for example R1=0,0,0 and R2=12,12,12, is roughly A=(r2-r1)*2.25 
																			#This can be empirically verified with e2spt_transformdistance.py
	
	if coarseStep < coarseStep1pix:
		coarseStep = coarseStep1pix
		print """The coarse step %f was finer than one pixel at the edge of the particle, 
		therefore it will be replaced with %f""" % (coarseStep,coarseStep1pix)
	
	CSrounded = math.floor( coarseStep * 100.00 )/100.00		#Round coarse step DOWN to scan slightly more finally than theoretically needed

	
	print "\n\n*****************"
	print"\n\nThe radius in pixels at size for fine alignment (taking --shrinkfine into account) is", radPixF
	print "Shrink is", options.shrink
	print "Shrink refine is", options.shrinkfine
	print "Therefore, the coarse step and itself rounded are", coarseStep, CSrounded
	print "And the fine step before and after rounding is", fineStep, fineStepRounded
	print "rango and its rounded are", rango, rangoRounded
	print "\n\n*****************\n\n"
	
	searchC = hdr['nx']/2.0 - 2.0
	searchF = 2
	
	if int( options.search ) > 1 :
		searchC = options.search
		print "searchC is", searchC
	else:
		if int(options.search) == 0:
			searchC = 0
			print "searchC is", searchC	

		elif int( options.search ) == 1:
			searchC = 1

		#elif options.mask:
		#	if 'mask.sharp' in options.mask[0]:
		#		if 'outer_radius' in options.mask[1]:
		#			om = options.mask[1]['outer_radius']
		#	
		#			if '-' in str(om):
		#				om = hdr['nx']/2 + om
		#			searchC = om/2.0
		#			print "\nBecause the radius for the mask is", om
		#			print "searchC is", searchC
		#			print "\n"
				
		if options.shrink and float(options.shrink) > 1.0:
			searchC = int( searchC / options.shrink )
	
			print "\nBecause shrink >1.0, searchC is actually", searchC
		
	if options.searchfine:
		searchF = options.searchfine
		print "\nSearchF is", searchF
		print "\n"
	else:
		searchF = 0
	
	options.align = 'rotate_translate_3d:search=' + str(searchC) +':delta=' + str(CSrounded) + ':dphi=' + str(CSrounded)
	if options.sym and options.sym is not 'c1' and options.sym is not 'C1' and 'sym' not in options.align:
		options.align += ':sym=' + str(options.sym)
	
	if options.falign and options.falign != None and options.falign != 'None' and options.falign != 'none':
		options.falign = 'refine_3d_grid:range=' + str(rangoRounded) + ':delta=' + str(fineStepRounded) + ':search=' + str(searchF)
	else:
		options.falign = 'None'
	
	if options.verbose:
		if options.verbose > 9:
			options.align += ':verbose=1'
			options.falign += ':verbose=1'
	
	return options
	
"""
def binaryTreeRef(options,nptclForRef,ptclnums,ic,etc,classize):
	
	factor=ic * classize
	if nptclForRef==1: 
		print "Error: More than 1 particle required if no reference provided through --ref."
		sys.exit(1)
			
	# we need to make an initial reference. Due to the parallelism scheme we're using in 3-D and the slow speed of the
	# individual alignments we use a slightly different strategy than in 2-D. We make a binary tree from the first 2^n particles and
	# compute pairwise alignments until we get an average out. 

	nseed=2**int(floor(log(len(ptclnums),2)))	# we stick with powers of 2 for this to make the tree easier to collapse
	if nseed>64 : 
		nseed=64
		print "Limiting seeding to the first 64 images"

	nseediter=int(log(nseed,2))			# number of iterations we'll need
	if options.verbose: 
		print "Seedtree to produce initial reference. Using %d particles in a %d level tree"%(nseed,nseediter)
	
	# We copy the particles for this class into bdb:seedtree_0
	'''
	for i,j in enumerate(ptclnums[:nseed]):
		emdata = EMData(options.input,j)
		
		#if options.inixforms:
		#	emdata.process_inplace("xform",{"transform":js["tomo_%04d"%i]})
		#	emdata.set_attr("test_xfm",js["tomo_%04d"%i])
		
		seedfile = "%s/seedtree_0_cl_%d.hdf" % (options.path,ic)
		emdata.write_image(seedfile, i)
		
		print "Creating this seed file for this class", seedfile, ic
	'''
	
	#for i in range( ptclnums[:nseed] ):
	
	ii=0
	seedfile = options.path + '/seedtree_0_cl_' + str(ic) + '.hdf'
	for j in ptclnums[:nseed]:
		emdata = EMData(options.input,j)
		emdata.write_image(seedfile,ii)
		print "have taken particle %d and written it into index %d of the seedfile" %(j,ii)
		ii+=1
		print "Creating this seed file for this class", seedfile, ic
	
	
	'''
	#Outer loop covering levels in the converging binary tree
	'''
	for i in range(nseediter):
		infile="%s/seedtree_%d_cl_%d.hdf"%(options.path,i,ic)
		print "Infile will be", infile
		
		outfile="%s/seedtree_%d_cl_%d.hdf"%(options.path,i+1,ic)
		print "Outfile will be", outfile
	
		tasks=[]
		results=[]
		transform = None
		# loop over volumes in the current level
		
		for j in range(0,nseed/(2**i),2):

			#Unfortunately this tree structure limits the parallelism to the number of pairs at the current level :^(
			if options.parallel:
				#task=Align3DTask(["cache",infile,j],["cache",infile,j+1],j/2,"Seed Tree pair %d at level %d"%(j/2,i),options.mask,options.normproc,options.preprocess,options.lowpass,options.highpass,
				#	options.npeakstorefine,options.align,options.aligncmp,options.falign,options.faligncmp,options.shrink,options.shrinkfine,transform,options.verbose-1,options.randomizewedge,options.wedgeangle,options.wedgei,options.wedgef)
				
				task=Align3DTask(["cache",infile,j],["cache",infile,j+1],j/2,"Seed Tree pair #%d at level %d"%(j/2,i),options,transform,0)
				tasks.append(task)
			else:
				#print "No parallelism specified"
				result=align3Dfunc(["cache",infile,j],["cache",infile,j+1],j/2,"Seed Tree pair #%d at level %d"%(j/2,i),options,transform,0)
				results.append(result['final'])
		'''		
		#Start the alignments for this level
		'''
		if options.parallel:
			tids=etc.send_tasks(tasks)
			if options.verbose: 
				print "%d tasks queued in seedtree level %d"%(len(tids),i) 

			'''Wait for alignments to finish and get results'''
			results=get_results(etc,tids,options.verbose,{},len(ptclnums),0,'binarytree')

			#results=get_results(etc,tids,options.verbose,{},nptclForRef,0)



			if options.verbose>2 : 
				print "Results:"
				pprint(results)
		else:
			#print "No parallelism specified"
			#results=tasks
			if options.verbose>2 : 
				print "Results:" 
				pprint(results)
						
		make_average_pairs(options,infile,outfile,results,options.averager,options.nocenterofmass)
		
	ref=EMData(outfile,0)		# result of the last iteration
	
	if options.savesteps :
		refname = options.path + '/class_' + str(ic).zfill( len( str(ic) )) + '.hdf'
		#refname = "%s#class_%02d.hdf"%(options.path,ic)
		ref.write_image(refname,-1)
	
	return ref
"""	


def postprocess(img,mask,normproc,postprocess):
	'''Postprocesses a volume in-place'''
	
	# Make a mask, use it to normalize (optionally), then apply it 
	maskimg=EMData(img["nx"],img["ny"],img["nz"])
	maskimg.to_one()
	if mask:
		maskimg.process_inplace(mask[0],mask[1])
		
	# normalize
	if normproc:
		if normproc[0]=="normalize.mask": 
			normproc[1]["mask"]=maskimg
		img.process_inplace(normproc[0],normproc[1])

	img.mult(maskimg)
	
	# Postprocess filter
	if postprocess: 
		img.process_inplace(postprocess[0],postprocess[1])
	return img


def sptmakepath(options, stem='spt'):
	if options.verbose:
		print "\n(e2spt_classaverage.py)(sptmakepath), stem is", stem
	
	#if options.path and ("/" in options.path or "#" in options.path):
	#	print "Path specifier should be the name of a subdirectory to use in the current directory. Neither '/' or '#' can be included. "
	#	sys.exit(1)


	files=os.listdir(os.getcwd())

	if not options.path:		
		options.path = stem + '_01'
		if options.verbose:
			print """\n(e2spt_classaverage.py)(sptmakepath)--path was not specified, 
			therefore it will have the default value""", options.path 	

	while options.path in files:
		if '_' not in options.path:
			options.path = options.path + '_00'
		else:
			jobtag=''
			components=options.path.split('_')
			if components[-1].isdigit():
				components[-1] = str(int(components[-1])+1).zfill(2)
			else:
				components.append('00')
						
			options.path = '_'.join(components)
			#options.path = path
	
	print "The new options.path is", options.path

	if options.path not in files:
		if options.verbose:
			print "I will make THIS path", options.path
		os.system('mkdir ' + options.path)
	
	return options



#def filters(options,fimage,preprocess,lowpass,highpass,shrink):
#	'''
#	#Preprocess, lowpass and/or highpass
#	'''
#	if preprocess:
#		print "(e2spt_classaverage.py)(filters) --preprocess provided:", options.preprocess
#		fimage.process_inplace(preprocess[0],preprocess[1])
#		#fimage.write_image(options.path + '/imgPrep.hdf',-1)
#		
#	if lowpass:
#		print "(e2spt_classaverage.py)(filters) --lowpass provided:", options.lowpass
#		fimage.process_inplace(lowpass[0],lowpass[1])
#		#fimage.write_image(options.path + '/imgPrepLp.hdf',-1)
#
#		
#	if highpass:
#		print "(e2spt_classaverage.py)(filters) --highpass provided:", options.highpass
#		fimage.process_inplace(highpass[0],highpass[1])
#		#fimage.write_image(options.path + '/imgPrepLpHp.hdf',-1)
#
#	
#	'''
#	#Shrinking both for initial alignment and reference
#	'''
#	if shrink and int( shrink ) > 1 :
#		print "(e2spt_classaverage.py)(filters) --shrink provided:", options.shrink
#		fimage.process_inplace("math.meanshrink",{"n":shrink})
#		#fimage.write_image(options.path + '/imgPrepLpHpSh.hdf',-1)
#
#
#	return fimage	


def preprocessing(image,options,mask,clipali,normproc,shrink,lowpass,highpass,preprocess,threshold,ptclindx,tag='ptcls',coarse='yes',round=-1):

	print "\n(e2spt_classaverage.py) preprocessing"
	print "Mask and its type are", mask, type(mask)
	if mask == 'None' or mask == 'none':
		mask = None
	if lowpass == 'None' or lowpass == 'none':
		lowpass = None
	if highpass == 'None' or highpass == 'none':
		highpass = None
	if preprocess == 'None' or preprocess == 'none':
		preprocess = None
	if threshold == 'None' or threshold == 'none':
		threshold = None
	
	if coarse != 'yes':
		print "lowpassfine received is", lowpass	
	
	apix = image['apix_x']
	
	'''
	Make the mask first 
	'''
	print "masking"
	maskimg = EMData( int(image["nx"]), int(image["ny"]), int(image["nz"]) )
	maskimg.to_one()
	print "Donde creating mask"
	
	#mask['origin_x']=0
	#mask['origin_y']=0
	#mask['origin_z']=0
	
	#mask['apix_x']=apix
	#mask['apix_y']=apix
	#mask['apix_z']=apix
	
	simage = image.copy()

	
	'''
	Clip the box size smaller if instructed to
	'''
	if clipali:
		print "(e2spt_classaverage.py)(preprocessing) --cliapli provided:", clipali
		
		sx = simage['nx']
		sy = simage['ny']
		sz = simage['nz']
		
		xc = sx/2
		yc = sy/2
		zc = sz/2
		
		#print "Box center is", xc,yc,sz
		newsize = clipali
		
		#print "new size is", newsize
		
		#print "original size was", sx,sy,sz
		
		r=Region( (2*xc - newsize)/2, (2*yc - newsize)/2, (2*zc - newsize)/2, newsize , newsize , newsize)
		simage.clip_inplace( r )
		
		#print "Clip ali region is", r
		#sys.exit()
		
		#print "\n\nMask size before clipping is", mask['nx'],mask['ny'],mask['nz']
		#if mask and mask != 'None' and mask != 'none':
		
		maskimg.clip_inplace( r )
			#print "\n\nMask size AFTER clipping is", mask['nx'],mask['ny'],mask['nz']
	
	
	if mask and mask != 'None' and mask != 'none':
		#if options.verbose:
		print "This is the mask I will apply: mask.process_inplace(%s,%s)" %(options.mask[0],options.mask[1]) 
		maskimg.process_inplace(mask[0],mask[1])
		
		print "(e2spt_classaverage.py)(preprocessing) --mask provided:", mask
		#mask.write_image(options.path + '/mask.hdf',-1)
	
	if options.maskfile:
		maskfileimg = EMData(options.maskfile,0)
		
		mx = maskfileimg['nx']
		my = maskfileimg['ny']
		mz = maskfileimg['nz']
		
		mxc = mx/2
		myc = my/2
		mzc = mz/2
		
		mnewsize = maskimg['nx']
		
		r=Region( (2*mxc - mnewsize)/2, (2*myc - mnewsize)/2, (2*mzc - mnewsize)/2, mnewsize , mnewsize , mnewsize)
		maskfileimg.clip_inplace( r )
		
		maskimg.mult( maskfileimg )
	
	
	'''
	Set the 'mask' parameter for --normproc if normalize.mask is being used
	'''
	if normproc and normproc != 'None' and normproc != 'none':
		if normproc[0]=="normalize.mask": 
			normproc[1]["mask"]=maskimg
	
	
	'''
	Mask-Normalize-Mask
	'''	
	if mask and mask != 'None' and mask != 'none' or options.maskfile:
		#if options.shrink:
		#	maskCoarse = mask.copy()
		#	maskCoarse.process_inplace('math.meanshrink',{'n':options.shrink})
		print "Masking once"
		#simage.write_image(options.path + '/imgRawClip.hdf',-1)
		simage.mult(maskimg)
		#simage.write_image(options.path + '/imgMsk1.hdf',-1)
	
	if normproc and normproc != 'None' and normproc != 'none':
		simage.process_inplace(normproc[0],normproc[1])
		#simage.write_image(options.path + '/imgMsk1norm.hdf',-1)

		print "(e2spt_classaverage.py)(preprocessing) --normproc provided:", normproc

	if mask and mask != 'None' and mask != 'none' or options.maskfile:
		print "Masking again after normalizing"
		simage.mult(maskimg)
		#simage.write_image(options.path + '/imgMsk1normMsk2.hdf',-1)

		
	#if lowpass or highpass or preprocess or int(shrink) > 1:
	#	simage = filters(options,simage,preprocess,lowpass,highpass,shrink)
	#	#simage.write_image(options.path + '/imgMsk1normMsk2Filts.hdf',-1)


	if threshold and threshold != 'None' and threshold != 'none':
		simage.process_inplace(threshold[0],threshold[1])
		#simage.write_image(options.path + '/imgMsk1normMsk2LpFiltsThr.hdf',-1)

	'''
	#Preprocess, lowpass and/or highpass
	'''
	if preprocess:
		print "(e2spt_classaverage.py)(filters) --preprocess provided:", options.preprocess
		simage.process_inplace(preprocess[0],preprocess[1])
		#fimage.write_image(options.path + '/imgPrep.hdf',-1)
		
	if lowpass:
		print "(e2spt_classaverage.py)(filters) --lowpass provided:", options.lowpass
		simage.process_inplace(lowpass[0],lowpass[1])
		#fimage.write_image(options.path + '/imgPrepLp.hdf',-1)
	
	if highpass:
		print "(e2spt_classaverage.py)(filters) --highpass provided:", options.highpass
		simage.process_inplace(highpass[0],highpass[1])
		#fimage.write_image(options.path + '/imgPrepLpHp.hdf',-1)
	
	'''
	#Shrinking
	'''
	if shrink and int( shrink ) > 1 :
		print "(e2spt_classaverage.py)(filters) --shrink provided:", options.shrink
		simage.process_inplace("math.meanshrink",{"n":shrink})
		#fimage.write_image(options.path + '/imgPrepLpHpSh.hdf',-1)
	
	
	preproclst = ''		
		
	#if ptclindx == -1:
	#	preproclst = options.path + "/.preproclstclassavg.txt"
	#
	#else:
	#	preproclst = options.path + "/.preproclsthac.txt"
	
	if coarse == 'yes':
		preproclst = options.path + "/.preproclstcoarse.txt"
	else:
		preproclst = options.path + "/.preproclstfine.txt"
	
	os.system('touch ' + preproclst)
	lines = []
	ptclindxtag = str(ptclindx) + '\n'
	if preproclst:
		f=open(preproclst,'r')
		lines=f.readlines()
		f.close()
		
		
	#if options.savepreprocessed and (mask or options.maskfile or normproc or threshold or lowpass or highpass or preprocess or shrink) and round < 1:
		
		
		
	#print "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n"
	#print "RECEIVED this ptclindxtag", ptclindxtag, tag
	#print "\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"	
		
		
		
		
	if options.savepreprocessed and preproclst and ptclindxtag not in lines and round < 1 and ptclindx > -1:
		#indx=-1
		
		print "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParticle indx is", ptclindx
		
		#sys.exit() 
		
		rootname=options.input.split('/')[-1]
		
		#if tag == 'ref':
		#	rootname = options.ref
		#	indx=0
			
		preprocname = rootname.replace('.hdf','_preprocCoarse.hdf')
		
		print "coarse is", coarse
		#sys.exit()
		
		if coarse != 'yes':
			preprocname = rootname.replace('.hdf','_preprocFine.hdf')
			print "Saving saved preproc for fine alignment"
			#sys.exit()
	
		if options.path not in preprocname:
			preprocname = options.path + '/' + preprocname
		
		simage.write_image(preprocname,ptclindx)
		
		f=open(preproclst,'a')
		f.write(ptclindxtag)
		f.close()
			
		
		#print "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n******************\n*******************\n"
		#print "Wrote this ptclindxtag", ptclindxtag
		#print "To this ptclst", preproclst
		#print "\n******************\n*******************\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
		#sys.exit()
	
	print "Done preprocessing"	
	return simage
	

#def makeAverage(options,ic,ptcl_file,path,align_parms,averager,saveali,saveallalign,keep,keepsig,symmetry,groups,breaksym,nocenterofmass,verbose=1,it=1):
def makeAverage(options,ic,align_parms,it=1):
	ptcl_file=options.input
	path=options.path
	#align_params=results
	averager=options.averager
	saveali=options.saveali
	saveallalign=options.saveallalign
	keep=options.keep
	keepsig=options.keepsig
	symmetry=options.sym
	groups=options.groups
	breaksym=options.breaksym
	#options.nocenterofmass
	verbose=options.verbose

	'''Will take a set of alignments and an input particle stack filename and produce a 
	new class-average. Particles may be excluded based on the keep and keepsig parameters. 
	If keepsig is not set, then keep represents an absolute fraction of particles to keep (0-1). 
	Otherwise it represents a sigma multiplier akin to e2classaverage.py.'''
	
	print "(e2pt_classaverage.py)(makeAverage) The results to parse are", align_parms
	
	#else:
	if keepsig:
		# inefficient memory-wise
		
		vals=[]
		vals2=[]
		for p in align_params:
			if p and p[0]:
				vals.append(p[0]['score'])
				vals2.append(p[0]['score']**2)
			
		val=sum(vals)
		val2=sum(vals2)
		#val=sum([p[0]["score"] for p in align_parms])
		#val2=sum([p[0]["score"]**2 for p in align_parms])

		mean=val/len(align_parms)
		sig=sqrt(val2/len(align_parms)-mean*mean)
		thresh=mean+sig*keep
		if verbose: 
			print "Keep threshold : %f (mean=%f  sigma=%f)"%(thresh,mean,sig)

	if keep:
		#print "p[0]['score'] is", align_parms[0]['score']
		print "Len of align_parms is", len(align_parms)
		
		vals=[]
		for p in align_parms:
			if 'score' in p[0]:
				pass
				#print "\nscore!"
			else:
				if p and p[0]:
					print "\nIn e2spt_classaverage.py, score not in a non-empty element of p, p[0]", p, p[0]
					#print "see, p[0] is", p[0]
					sys.exit()
		
			if p and p[0]:
				vals.append(p[0]['score'])
			
			#val=[p[0]["score"] for p in align_parms]
		vals.sort()
		thresh=vals[ int( keep * len(vals) ) - 1]
		if verbose: 
			print "Keep threshold : %f (min=%f  max=%f)"%(thresh,vals[0],vals[-1])

	"""Make variance image if available"""
	variance = EMData(ptcl_file,0).copy_head()
	if averager[0] == 'mean':
		averager[1]['sigma'] = variance
	
	print "averager is", averager
	avgr=Averagers.get(averager[0], averager[1])
	included=[]
	
	#print "The path to save the alignments is", path
	#jsdict = path + '/tomo_xforms.json'
	#js = js_open_dict(jsdict)
	
	kk=0		
	for i,ptcl_parms in enumerate(align_parms):
		ptcl=EMData(ptcl_file,i)
		
		if ptcl_parms and ptcl_parms[0]:
		
			ptcl.process_inplace("xform",{"transform":ptcl_parms[0]["xform.align3d"]})
			#print "I have applied this transform before averaging", ptcl_parms[0]["xform.align3d"]			
		
			if ptcl_parms[0]["score"]<=thresh: 
				avgr.add_image(ptcl)
				included.append(i)

			#js["tomo_%04d"%i] = ptcl_parms[0]['xform.align3d']
			if saveali:
				ptcl['origin_x'] = 0
				ptcl['origin_y'] = 0		# jesus - the origin needs to be reset to ZERO to avoid display issues in Chimera
				ptcl['origin_z'] = 0
				ptcl['spt_score'] = ptcl_parms[0]['score']
			
				#print "\nThe score is", ptcl_parms[0]['score']
				#print "Because the zero element is", ptcl_parms[0]
			
				ptcl['xform.align3d'] = Transform()
				#ptcl['spt_ali_param'] = ptcl_parms[0]['xform.align3d']
				ptcl['xform.align3d'] = ptcl_parms[0]['xform.align3d']
			
				classname = path + "/class_" +  str(ic).zfill( len( str(ic) )) + "_ptcl.hdf"
				#print "The class name is", classname
				#sys.exit()
				
				indx=i
				if options.groups > 1:
					indx=kk
					
				ptcl.write_image(classname,indx)
			
			kk+=1
			
					
	#js.close()
	
	if verbose: 
		print "Kept %d / %d particles in average"%(len(included),len(align_parms))

	print "Will finalize average"
	
	avg['spt_multiplicity']=len(included)
	avg=avgr.finish()
	print "done"
		
	if symmetry and not breaksym:
		avg=avg.process('xform.applysym',{'sym':symmetry})
	avg["class_ptcl_idxs"]=included
	avg["class_ptcl_src"]=ptcl_file
	
	if averager[0] == 'mean':
		varmapname = path + '/class_' + str(ic).zfill( len( str(ic) )) + '_varmap.hdf'
		variance.write_image( varmapname , it)
				
	#if not nocenterofmass:
	#	avg.process_inplace("xform.centerofmass")
	
	
	if options.autocenter:
		print "\n\n\n\nYou have selected to autocenter!\n", options.autocenter
		
		avgac = avg.copy()
		if options.autocentermask:
			avgac.process_inplace( options.autocentermask[0],options.autocentermask[1] )
			
		if options.autocenterpreprocess:
			apix = avg['apix_x']
			halfnyquist = apix*4
			highpassf = apix*a['nx']/2.0
			
			avgac.process_inplace( 'filter.highpass.gauss',{'cutoff_freq':highpassf,'apix':apix})
			avgac.process_inplace( 'filter.lowpass.gauss',{'cutoff_freq':halfnyquist,'apix':apix})
			avgac.process_inplace( 'math.meanshrink',{'n':2})
			
		avgac.process_inplace(options.autocenter[0],options.autocenter[1])
		
		tcenter = avgac['xform.align3d']
		print "Thus the average HAS BEEN be translated like this", tcenter

	avg['origin_x']=0
	avg['origin_y']=0
	avg['origin_z']=0
	
	return avg
		

"""
def make_average_pairs(options,ptcl_file,outfile,align_parms,averager,nocenterofmass):
	'''Will take a set of alignments and an input particle stack filename and produce a 
	new set of class-averages over pairs'''
	
	current = os.getcwd()
	print "\n(e2spt_classaverage.py) (make_average_pairs) current directory is", current
	findir = os.listdir(current)
	print "\noptions.path is", options.path
	findirpath = os.listdir(options.path)
	print "\nThe particle file where the particles ought to be read from is", ptcl_file
	print "\nLets see if ptcl_file is in path. Files in path are", findirpath
	
	print "\nalign_parms are", align_parms
	print "\nTheir len", len(align_parms)
	
	
	for i,ptcl_parms in enumerate(align_parms):
		
		print "\ni, ptcl_parms are", i, ptcl_parms
		
		#if ptcl_parms:
		ptcl0=EMData(ptcl_file,i*2)
		
		ptcl1=EMData(ptcl_file,i*2+1)
		ptcl1.process_inplace("xform",{"transform":ptcl_parms[0]["xform.align3d"]})
	
		#ptcl1.process_inplace("xform",{"transform":align_parms[0]["xform.align3d"]})
	
		# While this is only 2 images, we still use the averager in case something clever is going on
		print "averager is", averager
		avgr = Averagers.get(averager[0], averager[1])
		avgr.add_image(ptcl0)
		avgr.add_image(ptcl1)
	
		avg=avgr.finish()
		#postprocess(avg,optmask,optnormproc,optpostprocess)		#There should be NO postprocessing of the intermediate averages
	
		if not nocenterofmass:
			avg.process_inplace("xform.centerofmass")
	
		avg['origin_x']=0
		avg['origin_y']=0
		avg['origin_z']=0
	
		avg.write_image(outfile,i)
	return
"""		

def get_results(etc,tids,verbose,jsA,nptcls,savealiparams=0,ref=''):
	'''This will get results for a list of submitted tasks. Won't return until it has all requested results.
	aside from the use of options["ptcl"] this is fairly generalizable code.'''
	
	# wait for them to finish and get the results
	# results for each will just be a list of (qual,Transform) pairs
	
	results=[ [ '' ] ]*nptcls
	
	if ref == 'binarytree':
		results=[0]*len(tids)		# storage for results
	
	ncomplete=0
	tidsleft=tids[:]
	while 1:
		time.sleep(5)
		proglist=etc.check_task(tidsleft)
		nwait=0
		for i,prog in enumerate(proglist):
			if prog==-1: 
				nwait+=1
			
			if prog==100:
				r=etc.get_results(tidsleft[i])				# results for a completed task
				ptcl=r[0].classoptions["ptclnum"]			# get the particle number from the task rather than trying to work back to it
				results[ptcl]=r[1]["final"]					# this will be a list of (qual,Transform)
				
				#print "ptcl and type are", ptcl, type(ptcl)
				#print "results[ptcl] are", results[ptcl]
				#print "because results are", results
				
				if savealiparams and results and results[ptcl]:
					xformslabel = 'tomo_' + str( ptcl ).zfill( len( str(nptcls) ) )
			
					AliParams=results[ptcl][0]['xform.align3d']
					score = float(results[ptcl][0]['score'])
					jsA.setval( xformslabel, [ AliParams , score ] )
				
				ncomplete+=1
		
		tidsleft=[j for i,j in enumerate(tidsleft) if proglist[i]!=100]		# remove any completed tasks from the list we ask about
		if verbose:
			print "  %d tasks, %d complete, %d waiting to start        \r"%(len(tids),ncomplete,nwait)
			sys.stdout.flush()
	
		if len(tidsleft)==0: break
		
	return results


def wedgestats(volume,angle, wedgei, wedgef, options):
	#print "RECEIEVED, in wedge statistics, angle, wedgei and wedgef", angle, wedgei, wedgef
	vfft = volume.do_fft()
	print "Size of vfft is", vfft['nx'],vfft['ny'],vfft['nz']
	wedge = vfft.getwedge(angle, wedgei, wedgef)
	
	mean = vfft.get_attr('spt_wedge_mean')
	sigma = vfft.get_attr('spt_wedge_sigma')

	wedge.process_inplace('xform.phaseorigin.tocenter')
	symwedge = wedge.process('xform.mirror', {'axis':'x'})
	
	#print "Size of symwedge is", symwedge['nx'],symwedge['ny'],symwedge['nz']
	finalwedge = wedge + symwedge
	
	#finalwedge.process_inplace('threshold.binary',{'value':0.0})

	#print "Size of finalwedge is", finalwedge['nx'],finalwedge['ny'],finalwedge['nz']
	#finalwedge_otherhalf = finalwedge.copy()
	#finalwedge_otherhalf.rotate(0,180,0)
	
	'''
	Compute fft amps of the vol and center
	'''
	print "Size of vfft BEFORE real is", vfft['nx'],vfft['ny'],vfft['nz']
	vfft.ri2ap()
	ampsOrig = vfft.amplitude()
	amps = ampsOrig.process('xform.phaseorigin.tocenter')
	symamps = amps.process('xform.mirror', {'axis':'x'})
	finalamps = amps + symamps
		
	#print "Size of amps is", amps['nx'],amps['ny'],amps['nz']
	
	sigmas = options.aligncmp[1]['sigmas']
	print "Sigmas is", sigmas
	
	thresh = math.pow( mean + sigmas * sigma, 2.0 )
	print "Therefore thresh = mean + (sigmas*sigma)^2 is", thresh
	
	#print "Size of symamps is", symamps['nx'],symamps['ny'],symamps['nz']
	
	ampsThresh = finalamps.process('threshold.belowtozero',{'minval':thresh})
	
	#ampsOrigThresh.ap2ri()
	#ampsOrigThresh.do_iff()

	#print "Size of finalamps is", finalamps['nx'],finalamps['ny'],finalamps['nz']
	
	print "\nType of wedge is", type(finalwedge)
	print "\nType of amps is", type(finalamps)
	print "\nType of ampsThresh is", type(ampsThresh)
	
	if options.writewedge:
		
		completePath = os.getcwd() + '/' + options.path
		print "\nThe list of files in path is", os.listdir( completePath )
		 
		wedgename = os.getcwd() + '/' + options.path + '/wedge.hdf'
		finalwedge.write_image(wedgename,0)
		
		ampsname = os.getcwd() + '/' + options.path +'/fftamps.hdf'
		finalamps.write_image(ampsname,-1)
		
		ampsThreshname = os.getcwd() + '/' + options.path + '/fftampsThresh.hdf'
		ampsThresh.write_image(ampsThreshname,-1)	
	
	return(mean,sigma,thresh)

'''
CLASS TO PARALLELIZE ALIGNMENTS
'''
class Align3DTask(JSTask):
	"""This is a task object for the parallelism system. It is responsible for aligning one 3-D volume to another, with a variety of options"""

	#def __init__(self,fixedimage,image,ptcl,label,mask,normproc,preprocess,lowpass,highpass,npeakstorefine,align,aligncmp,falign,faligncmp,shrink,shrinkfine,transform,verbose,randomizewedge,wedgeangle,wedgei,wedgef):
	def __init__(self,fixedimage,image,ptclnum,label,options,transform,currentIter):
	
		"""fixedimage and image may be actual EMData objects, or ["cache",path,number]
		label is a descriptive string, not actually used in processing
		ptcl is not used in executing the task, but is for reference
		other parameters match command-line options from e2spt_classaverage.py
		Rather than being a string specifying an aligner, 'align' may be passed in as a 
		Transform object, representing a starting orientation for refinement"""
		
		
		#data={}
		
		data={"fixedimage":fixedimage,"image":image}
		
		JSTask.__init__(self,"ClassAv3d",data,{},"")

		#self.classoptions={"options":options,"ptcl":ptcl,"label":label,"mask":options.mask,"normproc":options.normproc,"preprocess":options.preprocess,"lowpass":options.lowpass,"highpass":options.highpass,"npeakstorefine":options.npeakstorefine,"align":options.align,"aligncmp":options.aligncmp,"falign":options.falign,"faligncmp":options.faligncmp,"shrink":options.shrink,"shrinkfine":options.shrinkfine,"transform":transform,"verbose":options.verbose,"randomizewedge":options.randomizewedge,"wedgeangle":options.wedgeangle,"wedgei":options.wedgei,"wedgef":options.wedgef}
		self.classoptions={"options":options,"ptclnum":ptclnum,"label":label,"transform":transform,"currentIter":currentIter}
	
	def execute(self,callback=None):
		"""This aligns one volume to a reference and returns the alignment parameters"""
		classoptions=self.classoptions

		if isinstance(self.data["fixedimage"],EMData):
			fixedimage=self.data["fixedimage"]
		else: 
			fixedimage=EMData(self.data["fixedimage"][1],self.data["fixedimage"][2])
		
		if isinstance(self.data["image"],EMData) :
			image=self.data["image"]
		else: 
			print "\nImage to align is", self.data["image"][1], self.data["image"][2]
			print "Inside path", classoptions['options'].path
			image=EMData(self.data["image"][1],self.data["image"][2])
			
		"""
		CALL the alignment function
		"""
		nptcls = EMUtil.get_image_count(classoptions['options'].input)
		print "\n(e2spt_classaverage.py)(Align3DTaks)(execute) nptcls is", nptcls
		#print "classoptions are", classoptions
		
		xformslabel = 'tomo_' + str(classoptions['ptclnum']).zfill( len( str(nptcls) ) )
		
		refpreprocess=0
		options=classoptions['options']
		
		try:	
			if not options.ref:
				print "\n\n\n\n(e2spt_classaverage.py)(Align3DTask) There is no reference; therfore, refpreprocess should be turned on", refpreprocess
				refpreprocess=1
		except:
			refpreprocess=1
		
		
		try:	
			if options.refpreprocess:
				refpreprocess=1
		except:
			refpreprocess=1
		
		currentIter=self.classoptions['currentIter']
		if int(options.iter) > 1 and currentIter > 0:
			refpreprocess=1
		
		if options.verbose:
			print "\n\n!!!!!!!!!!!!!!!!!!!!!!!!\n(e2spt_classaverage.py)(Align3DTask) Aligning ",classoptions['label']
			print "\n\!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!n\n\n\n\n\n\n"
		
		
		print "SENDING reference image in alignment and values are", fixedimage, fixedimage['minimum'],fixedimage['maximum'],fixedimage['sigma'],fixedimage['mean']
		if not fixedimage['maximum'] and not fixedimage['minimum']:
			print "Error. Empty reference."
			sys.exit()
		
		
		ret=alignment(fixedimage,image,classoptions['label'],classoptions['options'],xformslabel,classoptions['currentIter'],classoptions['transform'],'e2spt_classaverage',refpreprocess)

		bestfinal=ret[0]
		bestcoarse=ret[1]
		
		return {"final":bestfinal,"coarse":bestcoarse}

'''
FUNCTION FOR RUNNING ALIGNMENTS WITHOUT PARALLELISM
'''
def align3Dfunc(fixedimage,image,ptclnum,label,options,transform,currentIter):
	"""This aligns one volume to a reference and returns the alignment parameters"""

	if options.verbose: 
		print "(e2spt_classaverage.py)(align3Dfunc) Aligning ",label
	
	print "In align3Dfunc fixed image and its type are" , fixedimage, type(fixedimage)
	if type(fixedimage) is list:
		fixedimage=EMData(fixedimage[1],fixedimage[2])
	
	if type(image) is list:
		image=EMData(image[1],image[2])
	
	
	"""
	CALL the alignment function
	"""
	
	nptcls = EMUtil.get_image_count(options.input)
	xformslabel = 'tomo_' + str(ptclnum).zfill( len( str(nptcls) ) )
	
	refpreprocess=0
	
	if not options.ref:
		refpreprocess=1
		print "\n(e2spt_classaverage.py)(align3Dfunc) There is no reference; therfore, refpreprocess should be turned on", refpreprocess

	if options.refpreprocess:
		refpreprocess=1
	
	if int(options.iter) > 1 and currentIter > 0:
		refpreprocess=1
	
	
	print "SENDING reference image in alignment and values are", fixedimage, fixedimage['minimum'],fixedimage['maximum'],fixedimage['sigma'],fixedimage['mean']
	if not fixedimage['maximum'] and not fixedimage['minimum']:
		print "Error. Empty reference."
		sys.exit()
	
	ret=alignment(fixedimage,image,label,options,xformslabel,currentIter,transform,'e2spt_classaverage',refpreprocess)

	bestfinal=ret[0]
	bestcoarse=ret[1]
	
	return {"final":bestfinal,"coarse":bestcoarse}


'''
FUNCTION THAT DOES THE ACTUAL ALIGNMENT OF TWO GIVEN SUBVOLUMES -This is also used by e2spt_hac.py, any modification to it or its used parameters should be made with caution
'''
def alignment(fixedimage,image,label,options,xformslabel,iter,transform,prog='e2spt_classaverage',refpreprocess=0):
	
	if options.verbose: 
		print "\n\n!!!!\n(e2spt_classaverage.py)(alignment)Aligning ",label
		print "\n\!!!!!n\n\n\n\n\n\n"
	
	
	#refindx = -1
	#try:
	#	ptclindx = int(label.split(' ')[1])
	#
	#except:
		#
	#	refindx = int(xformslabel.split('_ptclA')[-1].split('_')[0])
	#	ptclindx = int(xformslabel.split('_ptclB')[-1].split('_')[0])
	#
	
	round=iter
	print "label is", label
	try:
		ptclindx = int(label.split(' ')[1])
		refindx = -1
	except:
		try:
			ptclindx = int( image['spt_ptcl_indxs'] )							#Deal with --savepreprocessed for e2spt_hac.py
			refindx = int( fixedimage['spt_ptcl_indxs'] )
			#round = int(xformslabel.split('_')[0].replace('round',''))
		except:
			try:
				ptclindx = int( label.split('#')[-1].split(' ')[0] )			#Deal with --savepreprocessed for binary tree initial model building (do NOT savepreprocessed)
				refindx = ptclinx +1
				round = -1
				
				ptclindx = refindx =-1
				
			except:
				ptclindx = refindx = 0
	
	"""
	PREPROCESSING CALL 
	Currently applied to both volumes. Often 'fixedimage' will be a reference, so may need to rethink whether it should be treated identically. 
	Similar issues in 2-D single particle refinement ... handled differently at the moment
	"""
	
	
	#########################################
	#Preprocess the reference or "fixed image"
	#########################################
	sfixedimage = fixedimage.copy()
	s2fixedimage = fixedimage.copy()
	
	
	#print "received reference image in alignment and values are", fixedimage, fixedimage['minimum'],fixedimage['maximum'],fixedimage['sigma'],fixedimage['mean']
	#print "received particle image in alignment and values are", image, image['minimum'],image['maximum'],image['sigma'],image['mean']

	
	#if not image['maximum'] and not image['minimum']:
	#	print "Error. Empty particle."
	#	sys.exit()
	
	#if not fixedimage['maximum'] and not fixedimage['minimum']:
	#	print "Error. Empty reference."
	#	sys.exit()
	
	
	if not refpreprocess:
		print "\nThere is NO refpreprocess! But an external reference WAS provided", options.ref
		
		if options.shrink and int(options.shrink) > 1:
			sfixedimage = sfixedimage.process('math.meanshrink',{'n':options.shrink})
		
		if options.procfinelikecoarse:
			s2fixedimage = sfixedimage.copy()	
		
		elif options.shrinkfine and int(options.shrinkfine) > 1:
			s2fixedimage = s2fixedimage.process('math.meanshrink',{'n':options.shrinkfine})
	
	elif refpreprocess:
		if options.clipali or options.threshold or options.normproc or options.mask or options.preprocess or options.lowpass or options.highpass or int(options.shrink) > 1:
			print "\nThere IS refpreprocess!"	
			sfixedimage = preprocessing(fixedimage,options,options.mask,options.clipali,options.normproc,options.shrink,options.lowpass,options.highpass,options.preprocess,options.threshold,refindx,'ref','yes',round)
		
		#Only preprocess again if there's fine alignment, AND IF the parameters for fine alignment are different
		if options.falign and options.falign != None and options.falign != 'None' and options.falign != 'none':
			if options.procfinelikecoarse:
				s2fixedimage = sfixedimage.copy()
				print "REFERENCE fine preprocessing is equal to coarse"
	
			elif options.preprocessfine or options.lowpassfine or options.highpassfine or int(options.shrinkfine) > 1:
				s2fixedimage = preprocessing(fixedimage,options,options.mask,options.clipali,options.normproc,options.shrinkfine,options.lowpassfine,options.highpassfine,options.preprocessfine,options.threshold,refindx,'ref','no',round)
		
	
	#########################################
	#Preprocess the particle or "moving image"
	#########################################
	simage = image
	s2image = image
	
	if options.clipali or options.threshold or options.normproc or options.mask or options.preprocess or options.lowpass or options.highpass or int(options.shrink) > 1:
	
		print "\n\n\n\n\n\n\n\n\n\n\nSending particle to preprocessing. It's size is", simage['nx'],simage['ny'],simage['nz']
	
		simage = preprocessing(image,options,options.mask,options.clipali,options.normproc,options.shrink,options.lowpass,options.highpass,options.preprocess,options.threshold,ptclindx,'ptcls','yes',round)
	
	#Only preprocess again if there's fine alignment, AND IF the parameters for fine alignment are different
	
	if options.falign and options.falign != None and options.falign != 'None' and options.falign != 'none': 
		if options.procfinelikecoarse:
			s2image = simage.copy()
			print "PARTICLE fine preprocessing is equal to coarse"
		elif options.preprocessfine or options.lowpassfine or options.highpassfine or int(options.shrinkfine) > 1:
			s2image = preprocessing(image,options,options.mask,options.clipali,options.normproc,options.shrinkfine,options.lowpassfine,options.highpassfine,options.preprocessfine,options.threshold,ptclindx,'ptcls','no',round)
			print "There was fine preprocessing"
		#sys.exit()
	
	if transform:
		#print "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere WAS a transform, see", transform
		#print "And its type is", type(transform)
		#if classoptions.verbose:
		#	print "Moving Xfrom", transform
		#options["align"][1]["inixform"] = options["transform"]
		if options.align:
			#print "There was classoptions.align"
			#print "and classoptions.align[1] is", classoptions.align[1]
			if options.align[1]:
				options.align[1]["transform"] = transform
		
		if int(options.shrink) > 1:
			#options["align"][1]["inixform"].set_trans( options["align"][1]["inixform"].get_trans()/float(options["shrinkfine"]) )
			options.align[1]["transform"].set_trans( options.align[1]["transform"].get_trans()/float(options.shrinkfine) )
		
	elif options.randomizewedge:
		rand_orient = OrientGens.get("rand",{"n":1,"phitoo":1})		#Fetches the orientation generator
		c1_sym = Symmetries.get("c1")					#Generates the asymmetric unit from which you wish to generate a random orientation
		random_transform = rand_orient.gen_orientations(c1_sym)[0]	#Generates a random orientation (in a Transform object) using the generator and asymmetric unit specified 
		if options.align:
			options.align[1].update({'transform' : random_transform})
		else:
			transform = random_transform
	
	if not options.align:
		if not transform:
			bestcoarse=[{"score":1.0e10,"xform.align3d":Transform()}]
		else:
			bestcoarse=[{"score":1.0e10,"xform.align3d":transform}]	

	else:
		'''
		Returns an ordered vector of Dicts of length options.npeakstorefine. 
		The Dicts in the vector have keys "score" and "xform.align3d" 
		'''
		
		#print "Will do coarse alignment"
		
		#print "\n\n\nRight before COARSE alignment, the boxsize of image is", simage['nx'],simage['ny'],simage['nz']
		#print "Right before COARSE alignment, the boxsize of FIXEDimage is", sfixedimage['nx'],sfixedimage['ny'],sfixedimage['nz']
		#print "Side adjustments will be attempted\n\n\n\n"
		
	
		#print "\n\n\nRight before COARSE ali, AFTER size adj, the boxsize of image is", simage['nx'],simage['ny'],simage['nz']
		#print "Right before COARSE alignment,  AFTER size adj, the boxsize of FIXEDimage is", sfixedimage['nx'],sfixedimage['ny'],sfixedimage['nz']
		
		if options.align:
			if simage['nx'] != sfixedimage['nx'] or simage['ny'] != sfixedimage['ny'] or simage['nz'] != sfixedimage['nz']:
				print "\n\nERROR: COARSE alignment images not the same size"
				print "\nThe particle's COARSE size is", simage['nx'],simage['ny'],simage['nz']
				print "\nThe reference's COARSE size is", sfixedimage['nx'],sfixedimage['ny'],sfixedimage['nz']
				sys.exit()	
			
		bestcoarse = simage.xform_align_nbest(options.align[0],sfixedimage,options.align[1],options.npeakstorefine,options.aligncmp[0],options.aligncmp[1])
		
		# Scale translation
		scaletrans=1.0
		if options.falign and options.falign != None and options.falign != 'None' and options.falign != 'none' and options.shrinkfine:
			scaletrans = options.shrink/float(options.shrinkfine)
		elif options.shrink and not options.falign:
			scaletrans=float(options.shrink)
			
		if scaletrans>1.0:
			print "\n\n\nShrink or shrinkfine are greater than 1 and not equal, and therefore translations need to be scaled!"
			print "Before, translations are", bestcoarse[0]['xform.align3d'].get_trans()
			print "Transform is", bestcoarse[0]['xform.align3d']
			
			for c in bestcoarse:
				c["xform.align3d"].set_trans(c["xform.align3d"].get_trans()*scaletrans)
			print "After, translations are", c['xform.align3d'].get_trans()
			print "Transform is", c['xform.align3d']

		elif options.shrink > 1.0 and options.shrinkfine > 1.0 and options.shrink == options.shrinkfine:
			print "\n\nshrink and shrink refine were equal!\n\n"
			
	# verbose printout
	if options.verbose > 1 :
		for i,j in enumerate(bestcoarse): 
			print "coarse %d. %1.5g\t%s"%(i,j["score"],str(j["xform.align3d"]))

	if options.falign and options.falign != None and options.falign != 'None' and options.falign != 'none':
		print "\n(e2spt_classaverage.py)(alignment) Will do fine alignment, over these many peaks", len(bestcoarse)
		# Now loop over the individual peaks and refine each
		bestfinal=[]
		peaknum=0
		print "\n(e2spt_classaverage.py)(alignment) options.falign is", options.falign, type(options.falign)
		for bc in bestcoarse:
			options.falign[1]["xform.align3d"] = bc["xform.align3d"]
			
			#print "\n\n\nRight BEFORE FINE alignment, the boxsize of the REFINE image is", s2image['nx'],s2image['ny'],s2image['nz']
			#print "And the transform passed in is", bc["xform.align3d"]
			#ali = s2image.align(options.falign[0],s2fixedimage,options.falign[1],options.faligncmp[0],options.faligncmp[1])
			
			
			print "\n(e2spt_classaverage.py)(alignment) s2image['nx'] == s2fixedimage['nx']", s2image['nx'] == s2fixedimage['nx'],  s2image['nx'], type(s2image['nx']), s2fixedimage['nx'], type(s2fixedimage['nx'])
			print "\n(e2spt_classaverage.py)(alignment) s2image['ny'] == s2fixedimage['ny']", s2image['ny'] == s2fixedimage['ny'],  s2image['ny'], type(s2image['ny']), s2fixedimage['ny'], type(s2fixedimage['ny'])
			print "\n(e2spt_classaverage.py)(alignment) s2image['nz'] == s2fixedimage['nz']", s2image['nz'] == s2fixedimage['nz'],  s2image['nz'], type(s2image['nz']), s2fixedimage['nz'], type(s2fixedimage['nz'])
			
			if int(s2image['nx']) != int(s2fixedimage['nx']) or int(s2image['ny']) != int(s2fixedimage['ny']) or int(s2image['nz']) != int(s2fixedimage['nz']):
				print "\n(e2spt_classaverage.py)(alignment) ERROR: FINE alignment images not the same size"
				print "\nThe particle's FINE size is", s2image['nx'],s2image['ny'],s2image['nz']
				print "\nThe reference's FINE size is", s2fixedimage['nx'],s2fixedimage['ny'],s2fixedimage['nz']
				sys.exit('MIE')
			
			ali = s2image.align(options.falign[0],s2fixedimage,options.falign[1],options.faligncmp[0],options.faligncmp[1])

			try: 					
				bestfinal.append({"score":ali["score"],"xform.align3d":ali["xform.align3d"],"coarse":bc})
				#print "\nThe appended score in TRY is", bestfinal[0]['score']					
			except:
				bestfinal.append({"score":1.0e10,"xform.align3d":bc["xform.align3d"],"coarse":bc})
				#print "\nThe appended score in EXCEPT is", bestfinal[0]['score']
			peaknum+=1
			
		if options.verbose:
			pass
			#print "Best final is", bestfinal
		
		
		#print "\n\n\nAfter fine alignment, before SHRINK compensation, the transform is", bestfinal[0]['xform.align3d']		
		if options.shrinkfine>1 :
			for c in bestfinal:
			
				newtrans = c["xform.align3d"].get_trans() * float(options.shrinkfine)
				#print "New trans and type are", newtrans, type(newtrans)
				c["xform.align3d"].set_trans(newtrans)
		
		print "AFTER fine alignment, after SHRINK compensation, the transform is", bestfinal[0]['xform.align3d']		
		print "\n\n\n"
		
		#verbose printout of fine refinement
		if options.verbose>1 :
			for i,j in enumerate(bestfinal): 
				print "fine %d. %1.5g\t%s"%(i,j["score"],str(j["xform.align3d"]))
	else: 
		bestfinal = bestcoarse
		if options.verbose:
			print "\nThere was no fine alignment; therefore, score is", bestfinal[0]['score']
	
	from operator import itemgetter							#If you just sort 'bestfinal' it will be sorted based on the 'coarse' key in the dictionaries of the list
															#because they come before the 'score' key of the dictionary (alphabetically)
	bestfinal = sorted(bestfinal, key=itemgetter('score'))
	
	print "Best final answer determined"
	if options.verbose:
		#print "\nThe best peaks sorted are"	#confirm the peaks are adequately sorted
		#for i in bestfinal:
		#	print i
		pass
	
	if bestfinal[0]["score"] == 1.0e10 and options.falign:
		print "Error: all refine alignments failed for %s. May need to consider altering filter/shrink parameters. Using coarse alignment, but results are likely invalid."%self.options["label"]
	
	if options.verbose: 
		#print "Best %1.5g\t %s"%(bestfinal[0]["score"],str(bestfinal[0]["xform.align3d"]))
		#print "Inside ALIGNMENT function in e2spt_classaverage, done aligning ",label
		pass	
	
	print "\n(e2spt_classaverage.py)(alignment)Rreturning from alignment."	
	return (bestfinal,bestcoarse)
	

jsonclasses["Align3DTask"]=Align3DTask.from_jsondict


def classmx_ptcls(classmx,n):
	"""Scans a classmx file to determine which images are in a specific class. Classmx may be a filename or an EMData object.
	returns a list of integers"""
	print "Classmx and its type received in classmx_ptcls are", classmx, type(classmx)
	if isinstance(classmx,str): 
		classmx=EMData(classmx,0)
	
	plist=[i.y for i in classmx.find_pixels_with_value(float(n))]
	
	return plist


	
if __name__ == "__main__":
    main()
    sys.stdout.flush()